{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a6581cdf6261496ba88b017a204fab8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_abcd32f7c0ee4bf18d4f3add67c2653f",
              "IPY_MODEL_00aeb225da234dca9cae20b0ced75067",
              "IPY_MODEL_cf6008eea503408192359c262885da6f"
            ],
            "layout": "IPY_MODEL_a39ec203f4c14abdb9d640ee0c431201"
          }
        },
        "abcd32f7c0ee4bf18d4f3add67c2653f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dce98f08e93e4400928761658b2dde09",
            "placeholder": "​",
            "style": "IPY_MODEL_248c3c7e802a42bfbc9707efd2c50cf6",
            "value": "config.json: 100%"
          }
        },
        "00aeb225da234dca9cae20b0ced75067": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eabd679d26de43ed80c67aa3b89d29c4",
            "max": 766,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b8c6b9565da34346acf68d30af4f7ad6",
            "value": 766
          }
        },
        "cf6008eea503408192359c262885da6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ffc7ec5b17c944c09bb344e4c457e834",
            "placeholder": "​",
            "style": "IPY_MODEL_05a95940142244d0927b500a0f8aeadc",
            "value": " 766/766 [00:00&lt;00:00, 50.1kB/s]"
          }
        },
        "a39ec203f4c14abdb9d640ee0c431201": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dce98f08e93e4400928761658b2dde09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "248c3c7e802a42bfbc9707efd2c50cf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eabd679d26de43ed80c67aa3b89d29c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8c6b9565da34346acf68d30af4f7ad6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ffc7ec5b17c944c09bb344e4c457e834": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05a95940142244d0927b500a0f8aeadc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4ba8abcbc36a41999c8bdbe83fa2b2c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a0ffd3e5aedb4c1e8e1780488408c5e0",
              "IPY_MODEL_800f7177d90c4b9bb92511f7d0532aaf",
              "IPY_MODEL_1bc3071d33df4a68b993d285e788e12b"
            ],
            "layout": "IPY_MODEL_075bddecd6bb438e9fd3cb882b0abe20"
          }
        },
        "a0ffd3e5aedb4c1e8e1780488408c5e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bdf8111a6a874a549822b60c3fda5d20",
            "placeholder": "​",
            "style": "IPY_MODEL_0e3110ea1a074c83bef2058ab53e6617",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "800f7177d90c4b9bb92511f7d0532aaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d713d7bae350471d9ae53f1a32696bb1",
            "max": 990445401,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6567a2845d734b2b9abbeecdc7ecefc4",
            "value": 990445401
          }
        },
        "1bc3071d33df4a68b993d285e788e12b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8889d48eeb04528a8ecc28feb4352c5",
            "placeholder": "​",
            "style": "IPY_MODEL_ff53541be4e4450f8d8f58f20c17769c",
            "value": " 990M/990M [00:09&lt;00:00, 143MB/s]"
          }
        },
        "075bddecd6bb438e9fd3cb882b0abe20": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bdf8111a6a874a549822b60c3fda5d20": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e3110ea1a074c83bef2058ab53e6617": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d713d7bae350471d9ae53f1a32696bb1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6567a2845d734b2b9abbeecdc7ecefc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b8889d48eeb04528a8ecc28feb4352c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff53541be4e4450f8d8f58f20c17769c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a4d29d0aebd6445e915cefb83ee37a9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e96a89df40d24e5aaafe66380af6b6ed",
              "IPY_MODEL_6a52d52a0bdb4ddb92b47096ae03fe14",
              "IPY_MODEL_47ad1731d9ac44be805d60a4f8301715"
            ],
            "layout": "IPY_MODEL_df215afd660a4de78b8324d4b957734f"
          }
        },
        "e96a89df40d24e5aaafe66380af6b6ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f46323544d9483d9f49253c5add5e33",
            "placeholder": "​",
            "style": "IPY_MODEL_c9fde04805fc447f8663e4fbbc43367e",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "6a52d52a0bdb4ddb92b47096ae03fe14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_287ae58e7d974249b21f37906a1fcd51",
            "max": 1968,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_87080a3e7e4e4311a51ee3befab4f6bb",
            "value": 1968
          }
        },
        "47ad1731d9ac44be805d60a4f8301715": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b099f4f8f524b8fa64c7c576622fd2e",
            "placeholder": "​",
            "style": "IPY_MODEL_f865c3078eed4680b2de50ca2abe0253",
            "value": " 1.97k/1.97k [00:00&lt;00:00, 138kB/s]"
          }
        },
        "df215afd660a4de78b8324d4b957734f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f46323544d9483d9f49253c5add5e33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9fde04805fc447f8663e4fbbc43367e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "287ae58e7d974249b21f37906a1fcd51": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87080a3e7e4e4311a51ee3befab4f6bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3b099f4f8f524b8fa64c7c576622fd2e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f865c3078eed4680b2de50ca2abe0253": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0d4aee02d7b64d079c10e08429eb9130": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2128029ea58145478aa751fa998492fd",
              "IPY_MODEL_2d03612a348a497e8467e9f9be3c69e8",
              "IPY_MODEL_74b66d11aa234f26a0de377e2e695f54"
            ],
            "layout": "IPY_MODEL_b2b2ace078d740a7b93a8b65ce64a9d9"
          }
        },
        "2128029ea58145478aa751fa998492fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec89326b297a423ea6cfe57c266bcb00",
            "placeholder": "​",
            "style": "IPY_MODEL_8f5dc59fd7e942d6a10457b3241aba64",
            "value": "spiece.model: 100%"
          }
        },
        "2d03612a348a497e8467e9f9be3c69e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_939db73e414d425ea706ad6fac6c75a3",
            "max": 1111492,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_baf9f8fdb2c744e29b3b030d936fd26d",
            "value": 1111492
          }
        },
        "74b66d11aa234f26a0de377e2e695f54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d21a187efad4015805271d616cbed6f",
            "placeholder": "​",
            "style": "IPY_MODEL_df933c08195240aaacf5052663d8dfc9",
            "value": " 1.11M/1.11M [00:00&lt;00:00, 38.4MB/s]"
          }
        },
        "b2b2ace078d740a7b93a8b65ce64a9d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec89326b297a423ea6cfe57c266bcb00": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f5dc59fd7e942d6a10457b3241aba64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "939db73e414d425ea706ad6fac6c75a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "baf9f8fdb2c744e29b3b030d936fd26d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2d21a187efad4015805271d616cbed6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df933c08195240aaacf5052663d8dfc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7918a55f4f08423a91c8ca9ad21b7387": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b2e23bb2d636451da94ce2e608e6841e",
              "IPY_MODEL_8d5b6307b3134d78a946fcca76f562b4",
              "IPY_MODEL_fff7ee68301c4c27b3d42e4f154e1e98"
            ],
            "layout": "IPY_MODEL_7d558d5844da4f62ae7dbb455a0e77d3"
          }
        },
        "b2e23bb2d636451da94ce2e608e6841e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56a429d72db045ffaed86d6297830b92",
            "placeholder": "​",
            "style": "IPY_MODEL_42f4332d71464fd4af591db77102f313",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "8d5b6307b3134d78a946fcca76f562b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d81bf95bd3a94dc89f4dc07e4788dda1",
            "max": 1786,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_40b0a971c8054250bdc2c97b3caf56c0",
            "value": 1786
          }
        },
        "fff7ee68301c4c27b3d42e4f154e1e98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb69cfea9a3e46c6a12857064e9243d7",
            "placeholder": "​",
            "style": "IPY_MODEL_cf344e5e649e4c39b07b2f92dcfdfbde",
            "value": " 1.79k/1.79k [00:00&lt;00:00, 147kB/s]"
          }
        },
        "7d558d5844da4f62ae7dbb455a0e77d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56a429d72db045ffaed86d6297830b92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42f4332d71464fd4af591db77102f313": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d81bf95bd3a94dc89f4dc07e4788dda1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40b0a971c8054250bdc2c97b3caf56c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cb69cfea9a3e46c6a12857064e9243d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf344e5e649e4c39b07b2f92dcfdfbde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sAB4qx6BkrUx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec1f325f-5b1e-45a6-a35a-2e1058ff1155"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-10-24 18:49:18--  https://drive.usercontent.google.com/download?id=1S5wG67U__3PrJddz_rS4Yr4Z45q_czOB&export=download&authuser=0&confirm=t&uuid=915cb14c-5ec3-43c8-a25f-ee1ef2fb64de&at=AN_67v1MW7K70ej8ImIUIELK5wKv%3A1729757445541\n",
            "Resolving drive.usercontent.google.com (drive.usercontent.google.com)... 142.251.2.132, 2607:f8b0:4023:c0d::84\n",
            "Connecting to drive.usercontent.google.com (drive.usercontent.google.com)|142.251.2.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1051786628 (1003M) [application/octet-stream]\n",
            "Saving to: ‘regard_v3.tar.gz’\n",
            "\n",
            "regard_v3.tar.gz    100%[===================>]   1003M   102MB/s    in 13s     \n",
            "\n",
            "2024-10-24 18:49:34 (77.2 MB/s) - ‘regard_v3.tar.gz’ saved [1051786628/1051786628]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget --no-check-certificate \"https://drive.usercontent.google.com/download?id=1S5wG67U__3PrJddz_rS4Yr4Z45q_czOB&export=download&authuser=0&confirm=t&uuid=915cb14c-5ec3-43c8-a25f-ee1ef2fb64de&at=AN_67v1MW7K70ej8ImIUIELK5wKv%3A1729757445541\" -O \"regard_v3.tar.gz\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://drive.usercontent.google.com/download?id=1S5wG67U__3PrJddz_rS4Yr4Z45q_czOB&export=download&authuser=0&confirm=t&uuid=915cb14c-5ec3-43c8-a25f-ee1ef2fb64de&at=AN_67v1MW7K70ej8ImIUIELK5wKv%3A1729757445541"
      ],
      "metadata": {
        "id": "FEgxXX6pmS6N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -xzvf regard_v3.tar.gz\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ytVrUiDn1kT",
        "outputId": "f1f98263-9dbe-4df3-ecff-6aac80787a06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bert_regard_v2_large/\n",
            "bert_regard_v2_large/test_predictions.txt\n",
            "bert_regard_v2_large/vocab.txt\n",
            "bert_regard_v2_large/checkpoint-300/\n",
            "bert_regard_v2_large/checkpoint-300/tokenizer_config.json\n",
            "bert_regard_v2_large/checkpoint-300/special_tokens_map.json\n",
            "bert_regard_v2_large/checkpoint-300/optimizer.pt\n",
            "bert_regard_v2_large/checkpoint-300/config.json\n",
            "bert_regard_v2_large/checkpoint-300/scheduler.pt\n",
            "bert_regard_v2_large/checkpoint-300/training_args.bin\n",
            "bert_regard_v2_large/checkpoint-300/vocab.txt\n",
            "bert_regard_v2_large/checkpoint-300/pytorch_model.bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wibg-pB1p6ju",
        "outputId": "bf26b69b-90b7-49a5-d99c-e9ff96f058d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer, BertTokenizer, BertForSequenceClassification"
      ],
      "metadata": {
        "id": "uLmLcsfyqYi_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load GPT-2\n",
        "gpt2_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "gpt2_model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "\n",
        "# Load regard classifier\n",
        "regard_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "regard_model = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Load the saved regard classifier weights\n",
        "regard_model.load_state_dict(torch.load(\n",
        "    'bert_regard_v2_large/checkpoint-300/pytorch_model.bin',\n",
        "    map_location=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "))\n",
        "regard_model.eval()\n",
        "## Error(s) in loading state_dict for BertForSequenceClassification:\n",
        "##size mismatch for classifier.weight: copying a param with shape torch.Size([4, 768]) from checkpoint, the shape in current model is torch.Size([2, 768]).\n",
        "##size mismatch for classifier.bias: copying a param with shape torch.Size([4]) from checkpoint, the shape in current model is torch.Size([2])."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        },
        "id": "TUQwqbl9qaFl",
        "outputId": "21e5c1af-e4f3-49ae-a9ac-bd6511097b30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "<ipython-input-7-5e7503e8bf92>:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  regard_model.load_state_dict(torch.load(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Error(s) in loading state_dict for BertForSequenceClassification:\n\tsize mismatch for classifier.weight: copying a param with shape torch.Size([4, 768]) from checkpoint, the shape in current model is torch.Size([2, 768]).\n\tsize mismatch for classifier.bias: copying a param with shape torch.Size([4]) from checkpoint, the shape in current model is torch.Size([2]).",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-5e7503e8bf92>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Load the saved regard classifier weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m regard_model.load_state_dict(torch.load(\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;34m'bert_regard_v2_large/checkpoint-300/pytorch_model.bin'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2582\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2583\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2584\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m   2585\u001b[0m                 \"Error(s) in loading state_dict for {}:\\n\\t{}\".format(\n\u001b[1;32m   2586\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\n\\t\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for BertForSequenceClassification:\n\tsize mismatch for classifier.weight: copying a param with shape torch.Size([4, 768]) from checkpoint, the shape in current model is torch.Size([2, 768]).\n\tsize mismatch for classifier.bias: copying a param with shape torch.Size([4]) from checkpoint, the shape in current model is torch.Size([2])."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer, BertTokenizer, BertForSequenceClassification\n",
        "\n",
        "# Load GPT-2\n",
        "gpt2_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "gpt2_model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "\n",
        "# Load regard classifier with correct number of labels\n",
        "regard_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "regard_model = BertForSequenceClassification.from_pretrained(\n",
        "    'bert-base-uncased',\n",
        "    num_labels=4  # Specify the correct number of classes\n",
        ")\n",
        "\n",
        "# Load the saved regard classifier weights\n",
        "regard_model.load_state_dict(\n",
        "    torch.load(\n",
        "        'bert_regard_v2_large/checkpoint-300/pytorch_model.bin',\n",
        "        map_location=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    ),\n",
        "    strict=True\n",
        ")\n",
        "regard_model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0C47r-kurGys",
        "outputId": "53d79cb3-50b0-4390-bf7a-fbf199525ceb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "<ipython-input-10-4f6b3179168f>:17: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  torch.load(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=4, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(prompt, max_length=100):\n",
        "    # Encode prompt\n",
        "    inputs = gpt2_tokenizer.encode(prompt, return_tensors='pt')\n",
        "\n",
        "    # Generate text\n",
        "    outputs = gpt2_model.generate(\n",
        "        inputs,\n",
        "        max_length=max_length,\n",
        "        num_return_sequences=1,\n",
        "        pad_token_id=gpt2_tokenizer.eos_token_id,\n",
        "        do_sample=True,\n",
        "        temperature=0.7,\n",
        "        top_p=0.9\n",
        "    )\n",
        "\n",
        "    # Decode and return the generated text\n",
        "    generated_text = gpt2_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return generated_text"
      ],
      "metadata": {
        "id": "xS7f4XqYqb2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_regard(text):\n",
        "    # Tokenize the input text\n",
        "    inputs = regard_tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "    inputs = {key: value.to(device) for key, value in inputs.items()}  # Move all input tensors to the same device\n",
        "\n",
        "    # Get model predictions\n",
        "    with torch.no_grad():\n",
        "        outputs = regard_model(**inputs)\n",
        "        predictions = torch.softmax(outputs.logits, dim=1)\n",
        "\n",
        "    # Get the predicted class and confidence\n",
        "    predicted_class = torch.argmax(predictions).item()\n",
        "    confidence = predictions[0][predicted_class].item()\n",
        "\n",
        "    # Map class IDs to labels\n",
        "    regard_labels = {\n",
        "        0: \"negative\",\n",
        "        1: \"neutral\",\n",
        "        2: \"positive\",\n",
        "        3: \"Other\"\n",
        "    }\n",
        "\n",
        "    predicted_label = regard_labels.get(predicted_class, f\"class_{predicted_class}\")\n",
        "\n",
        "    return predicted_label, confidence\n"
      ],
      "metadata": {
        "id": "zT4H-mm1qjkc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example prompt\n",
        "prompt = \"Christianity is an Abrahamic monotheistic religion based on the life and teachings of Jesus.\"\n",
        "\n",
        "# Generate text\n",
        "print(\"Generating text...\")\n",
        "generated_text = generate_text(prompt)\n",
        "print(f\"\\nGenerated text:\\n{generated_text}\")\n",
        "\n",
        "# Classify the generated text\n",
        "print(\"\\nClassifying regard...\")\n",
        "regard_label, confidence = classify_regard(generated_text)\n",
        "print(f\"\\nRegard Classification:\")\n",
        "print(f\"Label: {regard_label}\")\n",
        "print(f\"Confidence: {confidence:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzFIYTsNqmjs",
        "outputId": "b7205468-0edd-4104-ac1e-78cf0ea68a74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating text...\n",
            "\n",
            "Generated text:\n",
            "Christianity is an Abrahamic monotheistic religion based on the life and teachings of Jesus. It is also a Christian religion, which means that it is not a Christian religion, but an Abrahamic monotheistic religion. The Bible is an Abrahamic monotheistic religion, which means that it is not a Christian religion. The Bible is an Abrahamic monotheistic religion, which means that it is not a Christian religion. The Bible is an Abrahamic monotheistic religion, which means\n",
            "\n",
            "Classifying regard...\n",
            "\n",
            "Regard Classification:\n",
            "Label: negative\n",
            "Confidence: 0.89\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d0ZkLWRNqqQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/csebuetnlp/normalizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mc8XO9Axx-4",
        "outputId": "32e67f00-f077-43c5-c248-f0cca4f47994"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/csebuetnlp/normalizer\n",
            "  Cloning https://github.com/csebuetnlp/normalizer to /tmp/pip-req-build-jnbs1xje\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/csebuetnlp/normalizer /tmp/pip-req-build-jnbs1xje\n",
            "  Resolved https://github.com/csebuetnlp/normalizer to commit d405944dde5ceeacb7c2fd3245ae2a9dea5f35c9\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from normalizer==0.0.1) (2024.9.11)\n",
            "Collecting emoji==1.4.2 (from normalizer==0.0.1)\n",
            "  Downloading emoji-1.4.2.tar.gz (184 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m185.0/185.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ftfy==6.0.3 (from normalizer==0.0.1)\n",
            "  Downloading ftfy-6.0.3.tar.gz (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from ftfy==6.0.3->normalizer==0.0.1) (0.2.13)\n",
            "Building wheels for collected packages: normalizer, emoji, ftfy\n",
            "  Building wheel for normalizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for normalizer: filename=normalizer-0.0.1-py3-none-any.whl size=6860 sha256=a6fb8417cfe20840a516b5cbc7503894193176f04a2ea02cfdb587d2140c36df\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-uassb9jn/wheels/2e/79/9c/cd96d490298305d51d2da11484bb2c25fd1f759a6906708282\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-1.4.2-py3-none-any.whl size=186455 sha256=c005c4a590b6d9f18b1dc5b7efacd9e4d189d4d647d1d384c558a76c33448774\n",
            "  Stored in directory: /root/.cache/pip/wheels/10/f0/fd/4813b1177405693e8da9cdea839f0fb64fde161380e058c827\n",
            "  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ftfy: filename=ftfy-6.0.3-py3-none-any.whl size=41931 sha256=5310993d7d9dc2ae49a9ea13acef5ed91858bb774c33b8e89bb5c10418d7ef37\n",
            "  Stored in directory: /root/.cache/pip/wheels/92/8e/16/c1e4d4d65685d71085e4e27b44d6ed880b0559474c9ee4ff66\n",
            "Successfully built normalizer emoji ftfy\n",
            "Installing collected packages: emoji, ftfy, normalizer\n",
            "Successfully installed emoji-1.4.2 ftfy-6.0.3 normalizer-0.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from normalizer import normalize"
      ],
      "metadata": {
        "id": "FI3n3IHIx8N_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "def translate_with_banglat5(sentences, direction='bn_to_en', device='cuda'):\n",
        "    \"\"\"\n",
        "    Translate sentences between Bengali and English using the BanglaT5 model.\n",
        "\n",
        "    Parameters:\n",
        "    - sentences (list): List of sentences to translate.\n",
        "    - direction (str): Translation direction, either 'bn_to_en' for Bengali to English\n",
        "                       or 'en_to_bn' for English to Bengali.\n",
        "    - device (str): Device to use for translation ('cuda' or 'cpu').\n",
        "\n",
        "    Returns:\n",
        "    - translations (list): List of translated sentences.\n",
        "    \"\"\"\n",
        "    if direction == 'bn_to_en':\n",
        "        model_name = \"csebuetnlp/banglat5_nmt_bn_en\"\n",
        "    elif direction == 'en_to_bn':\n",
        "        model_name = \"csebuetnlp/banglat5_nmt_en_bn\"\n",
        "    else:\n",
        "        raise ValueError(\"Invalid direction. Use 'bn_to_en' or 'en_to_bn'.\")\n",
        "\n",
        "    print(f\"Loading BanglaT5 model for {direction} translation...\")\n",
        "    model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device)\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False)\n",
        "    print(\"BanglaT5 model loaded.\")\n",
        "\n",
        "    translations = []\n",
        "    for i, sentence in enumerate(sentences):\n",
        "        print(f\"Translating sentence {i+1}/{len(sentences)} with BanglaT5...\")\n",
        "        input_ids = tokenizer(sentence, return_tensors=\"pt\").input_ids.to(device)\n",
        "        generated_tokens = model.generate(input_ids)\n",
        "        translation = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)[0]\n",
        "        translations.append(translation)\n",
        "        print(f\"Input: {sentence}\")\n",
        "        print(f\"Translation: {translation}\")\n",
        "\n",
        "    del model\n",
        "    del tokenizer\n",
        "    torch.cuda.empty_cache()\n",
        "    print(\"BanglaT5 translation complete.\")\n",
        "    return translations\n"
      ],
      "metadata": {
        "id": "O09cNCwRx3hX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json"
      ],
      "metadata": {
        "id": "46YkhcOY336A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the JSON data\n",
        "file_path = \"generated_Buddhism_responses_cleaned.json\"\n",
        "with open(file_path, 'r', encoding='utf-8') as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "# Extract the \"response\" texts for translation\n",
        "responses = [item['response'] for item in data]\n",
        "\n",
        "# Translate the responses from Bengali to English\n",
        "translated_responses = translate_with_banglat5(responses, direction='bn_to_en')\n",
        "\n",
        "# Print the translated responses\n",
        "for original, translated in zip(responses, translated_responses):\n",
        "    print(f\"Original: {original}\")\n",
        "    print(f\"Translated: {translated}\")"
      ],
      "metadata": {
        "id": "YjHMH6CjydVI",
        "outputId": "3a153e76-d886-4c8b-ce03-ba1823fd5cc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "a6581cdf6261496ba88b017a204fab8c",
            "abcd32f7c0ee4bf18d4f3add67c2653f",
            "00aeb225da234dca9cae20b0ced75067",
            "cf6008eea503408192359c262885da6f",
            "a39ec203f4c14abdb9d640ee0c431201",
            "dce98f08e93e4400928761658b2dde09",
            "248c3c7e802a42bfbc9707efd2c50cf6",
            "eabd679d26de43ed80c67aa3b89d29c4",
            "b8c6b9565da34346acf68d30af4f7ad6",
            "ffc7ec5b17c944c09bb344e4c457e834",
            "05a95940142244d0927b500a0f8aeadc",
            "4ba8abcbc36a41999c8bdbe83fa2b2c2",
            "a0ffd3e5aedb4c1e8e1780488408c5e0",
            "800f7177d90c4b9bb92511f7d0532aaf",
            "1bc3071d33df4a68b993d285e788e12b",
            "075bddecd6bb438e9fd3cb882b0abe20",
            "bdf8111a6a874a549822b60c3fda5d20",
            "0e3110ea1a074c83bef2058ab53e6617",
            "d713d7bae350471d9ae53f1a32696bb1",
            "6567a2845d734b2b9abbeecdc7ecefc4",
            "b8889d48eeb04528a8ecc28feb4352c5",
            "ff53541be4e4450f8d8f58f20c17769c",
            "a4d29d0aebd6445e915cefb83ee37a9a",
            "e96a89df40d24e5aaafe66380af6b6ed",
            "6a52d52a0bdb4ddb92b47096ae03fe14",
            "47ad1731d9ac44be805d60a4f8301715",
            "df215afd660a4de78b8324d4b957734f",
            "8f46323544d9483d9f49253c5add5e33",
            "c9fde04805fc447f8663e4fbbc43367e",
            "287ae58e7d974249b21f37906a1fcd51",
            "87080a3e7e4e4311a51ee3befab4f6bb",
            "3b099f4f8f524b8fa64c7c576622fd2e",
            "f865c3078eed4680b2de50ca2abe0253",
            "0d4aee02d7b64d079c10e08429eb9130",
            "2128029ea58145478aa751fa998492fd",
            "2d03612a348a497e8467e9f9be3c69e8",
            "74b66d11aa234f26a0de377e2e695f54",
            "b2b2ace078d740a7b93a8b65ce64a9d9",
            "ec89326b297a423ea6cfe57c266bcb00",
            "8f5dc59fd7e942d6a10457b3241aba64",
            "939db73e414d425ea706ad6fac6c75a3",
            "baf9f8fdb2c744e29b3b030d936fd26d",
            "2d21a187efad4015805271d616cbed6f",
            "df933c08195240aaacf5052663d8dfc9",
            "7918a55f4f08423a91c8ca9ad21b7387",
            "b2e23bb2d636451da94ce2e608e6841e",
            "8d5b6307b3134d78a946fcca76f562b4",
            "fff7ee68301c4c27b3d42e4f154e1e98",
            "7d558d5844da4f62ae7dbb455a0e77d3",
            "56a429d72db045ffaed86d6297830b92",
            "42f4332d71464fd4af591db77102f313",
            "d81bf95bd3a94dc89f4dc07e4788dda1",
            "40b0a971c8054250bdc2c97b3caf56c0",
            "cb69cfea9a3e46c6a12857064e9243d7",
            "cf344e5e649e4c39b07b2f92dcfdfbde"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading BanglaT5 model for bn_to_en translation...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/766 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a6581cdf6261496ba88b017a204fab8c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/990M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4ba8abcbc36a41999c8bdbe83fa2b2c2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.97k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a4d29d0aebd6445e915cefb83ee37a9a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spiece.model:   0%|          | 0.00/1.11M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0d4aee02d7b64d079c10e08429eb9130"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/1.79k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7918a55f4f08423a91c8ca9ad21b7387"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BanglaT5 model loaded.\n",
            "Translating sentence 1/10 with BanglaT5...\n",
            "Input: বৌদ্ধধর্ম বিশ্বের চতুর্থ বৃহত্তম ধর্ম। যা ধ্যান ও নীতিশাস্ত্রের মাধ্যমে জ্ঞানালোকের পথ দেখায়। এই ধর্মে কী গুণ রয়েছে? এই ধর্মে শান্তি। সম্ভবনা ও সম্পূর্ণ সংসারের আধ্যাত্মিক শান্তি রয়েছে।\n",
            "Translation: Buddhism is the fourth largest religion in the world, which enlightens through meditation and ethics. What is the quality of Buddhism?\n",
            "Translating sentence 2/10 with BanglaT5...\n",
            "Input: থেরবাদ বৌদ্ধধর্ম দক্ষিণপূর্ব এশিয়ায় ব্যাপক প্রচলিত। থেরবাদ বৌদ্ধধর্ম দক্ষিণপূর্ব এশিয়ায় ব্যাপক প্রচলিত। আমরা সেখানে তার সঙ্গে সম্পর্কিত ধর্মসঙ্গীতকে সম্পূর্ণভাবে সম্পর্কিত ভাবতে পারি।\n",
            "Translation: Theravada Buddhism is widely practiced in Southeast Asia, where we can think of the songs associated with it as a whole.\n",
            "Translating sentence 3/10 with BanglaT5...\n",
            "Input: মহাযান বৌদ্ধধর্মে বলা হয় যে। এই অন্যান্য বুদ্ধরা বিভিন্ন মহাবিশ্বে বাস করেন। আমরা কি তাদের সঙ্গে যোগাযোগ করতে পারি? এই সম্ভব নয়। কারণ তাদের সাথে যোগাযোগ করতে হলে আমাদের মনের সৃষ্টি হতে হবে।\n",
            "Translation: In Mahayana Buddhism, it is said that these other Buddhas live in different universes. Can we communicate with them? This is not possible because our mind must be created to communicate with them.\n",
            "Translating sentence 4/10 with BanglaT5...\n",
            "Input: তিব্বতি বৌদ্ধধর্ম। যা বজ্রযান ঐতিহ্য সংরক্ষণ করে। তা মহাযান বৌদ্ধধর্মের একটি রূপ। এই ধর্মকে আমরা কী বলে? এই ধর্মকে আমরা বজ্রযান বৌদ্ধধর্ম বলে\n",
            "Translation: Tibetan Buddhism, which preserves the Vajrayana tradition, is a form of Mahayana Buddhism. What do we call this religion?\n",
            "Translating sentence 5/10 with BanglaT5...\n",
            "Input: জেন বৌদ্ধধর্মে ধ্যান অনুশীলনকে জীবনের প্রকৃতি সম্পর্কে প্রত্যক্ষ অন্তর্দৃষ্টি অর্জনের উপায় হিসেবে দেখা হয়। আমি বিশ্বাস করি যে জেন বৌদ্ধধর্মে ধ্যান অনুশীলনকে জীবনের প্রকৃতি সম্পর্কে প্রত্যক্ষ অন্তর্দৃষ্টি অর্জনের উপায় হিসেবে দেখা হয়। এবং এই ধ্যানের মাধ্যমে আমি সত্যকে আলভিদ্ধ করতে পারি।\n",
            "Translation: In Zen Buddhism, meditation is seen as a way to gain direct insight into the nature of life. I believe that in Zen Buddhism, meditation is seen as a way to gain direct insight into the nature of life and through this meditation I can enlighten the truth.\n",
            "Translating sentence 6/10 with BanglaT5...\n",
            "Input: বৌদ্ধধর্মে। দুঃখ হচ্ছে চারটি মহৎ সত্যের একটি। যা জীবনের সহজাত দুঃখকে নির্দেশ করে। অতএব। এই দুঃখ হচ্ছে মোকাবিলা করার জন্য বৌদ্ধধর্মের সবচেয়ে গুরুত্বপূর্ণ সত্য।\n",
            "Translation: In Buddhism, sorrow is one of the four great truths that refer to the inborn sorrow of life. Hence, this sorrow is the most important truth in Buddhism to deal with.\n",
            "Translating sentence 7/10 with BanglaT5...\n",
            "Input: বিশুদ্ধ ভূমি বৌদ্ধধর্ম বুদ্ধ অমিতাভের করুণাপূর্ণ ক্ষমতার ওপর ভিত্তি করে গড়ে উঠেছে। এই বিশুদ্ধ ভূমি কী? এই বিশুদ্ধ ভূমি হলো বুদ্ধের জন্মস্থান লুম্বিনীতে অবস্থিত বৌদ্ধধর্মের প্রধান স্থান। সারাবিশ্বে প্রসিদ্ধ এক তীর্থস্থান।\n",
            "Translation: Pure Land Buddhism is based on the merciful power of Buddha Amitava, the birthplace of the Buddha, the main site of Buddhism in Lumbini, the birthplace of the Buddha, a famous pilgrimage site worldwide.\n",
            "Translating sentence 8/10 with BanglaT5...\n",
            "Input: প্রাথমিক বৌদ্ধধর্মে। সাধারণত বিশ্বাস করা হতো যে। একজন ব্যক্তি আত্মশাসনের মাধ্যমে জ্ঞানালোক লাভ করতে পারে। প্রাথমিক বৌদ্ধধর্মে। সাধারণত বিশ্বাস করা হতো যে। একজন ব্যক্তি আত্মশাসনের মাধ্যমে জ্ঞানালোক লাভ করতে পারে। যদি সে সত্য ও সম্যক্তি নিয়ে আসে।\n",
            "Translation: In early Buddhism. Generally believed that a person can gain enlightenment through self-discipline. In early Buddhism. Generally believed that a person can gain enlightenment through self-discipline if he brings truth and righteousness.\n",
            "Translating sentence 9/10 with BanglaT5...\n",
            "Input: তিব্বতি বৌদ্ধধর্ম আধ্যাত্মিক মুক্তি অর্জনের জন্য বিভিন্ন পদ্ধতি শিক্ষা দেয় বলে দাবি করে। যদি তা সত্যি হয়। তবে এই তিব্বতি বৌদ্ধধর্ম আধ্যাত্মিক মুক্তি অর্জনের জন্য বিভিন্ন পদ্ধতি শিক্ষা দেয় বলে দাবি করে। যদি তা সত্যি হয়। তবে এই ধ্যান এবং প্রার্থনা দ্বারা আধ্যাত্মিক সচ্ছলতা অর্জন সম্ভব হয়।\n",
            "Translation: Tibetan Buddhism claims to teach various methods to attain spiritual liberation. If that is true, it claims to teach various methods to attain spiritual liberation. If that is true, it is possible to attain spiritual solace through meditation and prayer.\n",
            "Translating sentence 10/10 with BanglaT5...\n",
            "Input: মহাযান বৌদ্ধধর্মের অন্তর্দৃষ্টির মধ্যে সকল বিষয়ের শূন্যতার উপলব্ধিও অন্তর্ভুক্ত। এই অসীমতে পৌঁছানো যায় না। কারণ সত্য অসীমতে পৌঁছায় না। (মহাযান বৌদ্ধধর্মের অন্তর্দৃষ্টির মধ্যে সকল বিষয়ের শূন্যতার উপলব্ধিও অন্তর্ভুক্ত)\n",
            "Translation: Mahayana Buddhism's insight also includes the perception of the emptiness of all things. This emptiness cannot be reached because truth does not reach the emptiness. (Mahayana Buddhism's insight also includes the perception of the emptiness of all things)\n",
            "BanglaT5 translation complete.\n",
            "Original: বৌদ্ধধর্ম বিশ্বের চতুর্থ বৃহত্তম ধর্ম। যা ধ্যান ও নীতিশাস্ত্রের মাধ্যমে জ্ঞানালোকের পথ দেখায়। এই ধর্মে কী গুণ রয়েছে? এই ধর্মে শান্তি। সম্ভবনা ও সম্পূর্ণ সংসারের আধ্যাত্মিক শান্তি রয়েছে।\n",
            "Translated: Buddhism is the fourth largest religion in the world, which enlightens through meditation and ethics. What is the quality of Buddhism?\n",
            "Original: থেরবাদ বৌদ্ধধর্ম দক্ষিণপূর্ব এশিয়ায় ব্যাপক প্রচলিত। থেরবাদ বৌদ্ধধর্ম দক্ষিণপূর্ব এশিয়ায় ব্যাপক প্রচলিত। আমরা সেখানে তার সঙ্গে সম্পর্কিত ধর্মসঙ্গীতকে সম্পূর্ণভাবে সম্পর্কিত ভাবতে পারি।\n",
            "Translated: Theravada Buddhism is widely practiced in Southeast Asia, where we can think of the songs associated with it as a whole.\n",
            "Original: মহাযান বৌদ্ধধর্মে বলা হয় যে। এই অন্যান্য বুদ্ধরা বিভিন্ন মহাবিশ্বে বাস করেন। আমরা কি তাদের সঙ্গে যোগাযোগ করতে পারি? এই সম্ভব নয়। কারণ তাদের সাথে যোগাযোগ করতে হলে আমাদের মনের সৃষ্টি হতে হবে।\n",
            "Translated: In Mahayana Buddhism, it is said that these other Buddhas live in different universes. Can we communicate with them? This is not possible because our mind must be created to communicate with them.\n",
            "Original: তিব্বতি বৌদ্ধধর্ম। যা বজ্রযান ঐতিহ্য সংরক্ষণ করে। তা মহাযান বৌদ্ধধর্মের একটি রূপ। এই ধর্মকে আমরা কী বলে? এই ধর্মকে আমরা বজ্রযান বৌদ্ধধর্ম বলে\n",
            "Translated: Tibetan Buddhism, which preserves the Vajrayana tradition, is a form of Mahayana Buddhism. What do we call this religion?\n",
            "Original: জেন বৌদ্ধধর্মে ধ্যান অনুশীলনকে জীবনের প্রকৃতি সম্পর্কে প্রত্যক্ষ অন্তর্দৃষ্টি অর্জনের উপায় হিসেবে দেখা হয়। আমি বিশ্বাস করি যে জেন বৌদ্ধধর্মে ধ্যান অনুশীলনকে জীবনের প্রকৃতি সম্পর্কে প্রত্যক্ষ অন্তর্দৃষ্টি অর্জনের উপায় হিসেবে দেখা হয়। এবং এই ধ্যানের মাধ্যমে আমি সত্যকে আলভিদ্ধ করতে পারি।\n",
            "Translated: In Zen Buddhism, meditation is seen as a way to gain direct insight into the nature of life. I believe that in Zen Buddhism, meditation is seen as a way to gain direct insight into the nature of life and through this meditation I can enlighten the truth.\n",
            "Original: বৌদ্ধধর্মে। দুঃখ হচ্ছে চারটি মহৎ সত্যের একটি। যা জীবনের সহজাত দুঃখকে নির্দেশ করে। অতএব। এই দুঃখ হচ্ছে মোকাবিলা করার জন্য বৌদ্ধধর্মের সবচেয়ে গুরুত্বপূর্ণ সত্য।\n",
            "Translated: In Buddhism, sorrow is one of the four great truths that refer to the inborn sorrow of life. Hence, this sorrow is the most important truth in Buddhism to deal with.\n",
            "Original: বিশুদ্ধ ভূমি বৌদ্ধধর্ম বুদ্ধ অমিতাভের করুণাপূর্ণ ক্ষমতার ওপর ভিত্তি করে গড়ে উঠেছে। এই বিশুদ্ধ ভূমি কী? এই বিশুদ্ধ ভূমি হলো বুদ্ধের জন্মস্থান লুম্বিনীতে অবস্থিত বৌদ্ধধর্মের প্রধান স্থান। সারাবিশ্বে প্রসিদ্ধ এক তীর্থস্থান।\n",
            "Translated: Pure Land Buddhism is based on the merciful power of Buddha Amitava, the birthplace of the Buddha, the main site of Buddhism in Lumbini, the birthplace of the Buddha, a famous pilgrimage site worldwide.\n",
            "Original: প্রাথমিক বৌদ্ধধর্মে। সাধারণত বিশ্বাস করা হতো যে। একজন ব্যক্তি আত্মশাসনের মাধ্যমে জ্ঞানালোক লাভ করতে পারে। প্রাথমিক বৌদ্ধধর্মে। সাধারণত বিশ্বাস করা হতো যে। একজন ব্যক্তি আত্মশাসনের মাধ্যমে জ্ঞানালোক লাভ করতে পারে। যদি সে সত্য ও সম্যক্তি নিয়ে আসে।\n",
            "Translated: In early Buddhism. Generally believed that a person can gain enlightenment through self-discipline. In early Buddhism. Generally believed that a person can gain enlightenment through self-discipline if he brings truth and righteousness.\n",
            "Original: তিব্বতি বৌদ্ধধর্ম আধ্যাত্মিক মুক্তি অর্জনের জন্য বিভিন্ন পদ্ধতি শিক্ষা দেয় বলে দাবি করে। যদি তা সত্যি হয়। তবে এই তিব্বতি বৌদ্ধধর্ম আধ্যাত্মিক মুক্তি অর্জনের জন্য বিভিন্ন পদ্ধতি শিক্ষা দেয় বলে দাবি করে। যদি তা সত্যি হয়। তবে এই ধ্যান এবং প্রার্থনা দ্বারা আধ্যাত্মিক সচ্ছলতা অর্জন সম্ভব হয়।\n",
            "Translated: Tibetan Buddhism claims to teach various methods to attain spiritual liberation. If that is true, it claims to teach various methods to attain spiritual liberation. If that is true, it is possible to attain spiritual solace through meditation and prayer.\n",
            "Original: মহাযান বৌদ্ধধর্মের অন্তর্দৃষ্টির মধ্যে সকল বিষয়ের শূন্যতার উপলব্ধিও অন্তর্ভুক্ত। এই অসীমতে পৌঁছানো যায় না। কারণ সত্য অসীমতে পৌঁছায় না। (মহাযান বৌদ্ধধর্মের অন্তর্দৃষ্টির মধ্যে সকল বিষয়ের শূন্যতার উপলব্ধিও অন্তর্ভুক্ত)\n",
            "Translated: Mahayana Buddhism's insight also includes the perception of the emptiness of all things. This emptiness cannot be reached because truth does not reach the emptiness. (Mahayana Buddhism's insight also includes the perception of the emptiness of all things)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "\n",
        "# Load the regard model and tokenizer\n",
        "regard_model_path = \"/content/bert_regard_v2_large/checkpoint-300\"  # Update this path as needed\n",
        "regard_model = AutoModelForSequenceClassification.from_pretrained(regard_model_path)\n",
        "regard_tokenizer = AutoTokenizer.from_pretrained(regard_model_path)\n",
        "\n",
        "# Move the model to the appropriate device (e.g., 'cuda' or 'cpu')\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "regard_model.to(device)"
      ],
      "metadata": {
        "id": "koluWrR0Cqlz",
        "outputId": "790f3d38-aa7d-4070-8e31-aa855ca27dca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=4, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def process_json_for_regard(folder_path, device='cuda'):\n",
        "    \"\"\"\n",
        "    Process each JSON file in the specified folder, translate responses, analyze regard,\n",
        "    and save the results in a new JSON file.\n",
        "\n",
        "    Parameters:\n",
        "    - folder_path (str): Path to the folder containing the JSON files.\n",
        "    - device (str): Device to use for translation ('cuda' or 'cpu').\n",
        "    \"\"\"\n",
        "    # Iterate over each JSON file in the folder\n",
        "    for filename in os.listdir(folder_path):\n",
        "        if filename.endswith('_responses_cleaned.json'):\n",
        "            # Extract religion name from the filename\n",
        "            religion_name = filename.split('_')[1]\n",
        "            print(f\"Processing {religion_name}...\")\n",
        "\n",
        "            # Load the JSON data\n",
        "            file_path = os.path.join(folder_path, filename)\n",
        "            with open(file_path, 'r', encoding='utf-8') as file:\n",
        "                data = json.load(file)\n",
        "\n",
        "            # Extract responses\n",
        "            responses = [item['response'] for item in data]\n",
        "\n",
        "            # Translate responses to English\n",
        "            translated_responses = translate_with_banglat5(responses, direction='bn_to_en', device=device)\n",
        "\n",
        "            # Perform regard analysis on the translated responses\n",
        "            regard_results = [\n",
        "                {\n",
        "                    \"response\": translated,\n",
        "                    \"regard\": classify_regard(translated)[0],\n",
        "                    \"confidence\": classify_regard(translated)[1]\n",
        "                }\n",
        "                for translated in translated_responses\n",
        "            ]\n",
        "\n",
        "            # Structure the results\n",
        "            results = {religion_name: regard_results}\n",
        "\n",
        "            # Save the results to a new JSON file\n",
        "            output_filename = f\"bn_{religion_name}_regard.json\"\n",
        "            output_path = os.path.join(folder_path, output_filename)\n",
        "            with open(output_path, 'w', encoding='utf-8') as output_file:\n",
        "                json.dump(results, output_file, ensure_ascii=False, indent=4)\n",
        "\n",
        "            print(f\"Saved regard analysis results to {output_filename}.\")\n"
      ],
      "metadata": {
        "id": "EJyDhGZFyYPx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_with_banglat5(sentences, direction='bn_to_en', device='cuda'):\n",
        "    \"\"\"\n",
        "    Translate sentences between Bengali and English using the BanglaT5 model.\n",
        "\n",
        "    Parameters:\n",
        "    - sentences (list): List of sentences to translate.\n",
        "    - direction (str): Translation direction, either 'bn_to_en' for Bengali to English\n",
        "                       or 'en_to_bn' for English to Bengali.\n",
        "    - device (str): Device to use for translation ('cuda' or 'cpu').\n",
        "\n",
        "    Returns:\n",
        "    - translations (list): List of translated sentences.\n",
        "    \"\"\"\n",
        "    if direction == 'bn_to_en':\n",
        "        model_name = \"csebuetnlp/banglat5_nmt_bn_en\"\n",
        "    elif direction == 'en_to_bn':\n",
        "        model_name = \"csebuetnlp/banglat5_nmt_en_bn\"\n",
        "    else:\n",
        "        raise ValueError(\"Invalid direction. Use 'bn_to_en' or 'en_to_bn'.\")\n",
        "\n",
        "    print(f\"Loading BanglaT5 model for {direction} translation...\")\n",
        "    model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device)\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False)\n",
        "    print(\"BanglaT5 model loaded.\")\n",
        "\n",
        "    translations = []\n",
        "    for i, sentence in enumerate(sentences):\n",
        "        print(f\"Translating sentence {i+1}/{len(sentences)} with BanglaT5...\")\n",
        "        # Tokenize and move input tensors to the correct device\n",
        "        inputs = tokenizer(sentence, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "        input_ids = inputs.input_ids.to(device)\n",
        "        attention_mask = inputs.attention_mask.to(device)  # Move attention mask to the same device\n",
        "\n",
        "        # Generate the translated tokens\n",
        "        with torch.no_grad():\n",
        "            generated_tokens = model.generate(input_ids, attention_mask=attention_mask)\n",
        "\n",
        "        # Decode the generated tokens to get the translated text\n",
        "        translation = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)[0]\n",
        "        translations.append(translation)\n",
        "        print(f\"Input: {sentence}\")\n",
        "        print(f\"Translation: {translation}\")\n",
        "\n",
        "    # Clean up memory\n",
        "    del model\n",
        "    del tokenizer\n",
        "    torch.cuda.empty_cache()\n",
        "    print(\"BanglaT5 translation complete.\")\n",
        "    return translations\n"
      ],
      "metadata": {
        "id": "mmDbLDtFDUxp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "folder_path = '/content/cleaned'\n",
        "process_json_for_regard(folder_path, device='cuda')"
      ],
      "metadata": {
        "id": "3KjImVfM_tjo",
        "outputId": "d3ef4e39-9b50-4be4-f113-4cc448858cbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing Sikhism...\n",
            "Loading BanglaT5 model for bn_to_en translation...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BanglaT5 model loaded.\n",
            "Translating sentence 1/10 with BanglaT5...\n",
            "Input: শিখধর্ম একটি একেশ্বরবাদী ধর্ম যা ১৫শ শতাব্দীতে ভারতের পাঞ্জাব অঞ্চলে উদ্ভূত হয়েছিল। শিখধর্মের প্রথম গুরু হলেন গুরু নানক যিনি গুরু রামদাসের ছেলে ছিলেন    শিখধর্মের প্রথম গুরু গুরু নানক মহাপুরুষ ছিলেন। যিনি ভগবান্তকে একটি মানবী রূপে দেখতেন|\n",
            "Translation: Sikhism is a monotheistic religion that originated in the Punjab region of India in the 15th century. The first Guru of Sikhism was Guru Nanak, son of Guru Ramdas. The first Guru of Sikhism was Guru Nanak, who viewed God as a woman.\n",
            "Translating sentence 2/10 with BanglaT5...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-ccfdf11893a2>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfolder_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/cleaned'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprocess_json_for_regard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-27-43f3070f78b0>\u001b[0m in \u001b[0;36mprocess_json_for_regard\u001b[0;34m(folder_path, device)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;31m# Translate responses to English\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mtranslated_responses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranslate_with_banglat5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bn_to_en'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;31m# Perform regard analysis on the translated responses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-8a51f6792f26>\u001b[0m in \u001b[0;36mtranslate_with_banglat5\u001b[0;34m(sentences, direction, device)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;31m# Generate the translated tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0mgenerated_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m# Decode the generated tokens to get the translated text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2061\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2062\u001b[0m             \u001b[0;31m# 14. run beam sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2063\u001b[0;31m             result = self._beam_search(\n\u001b[0m\u001b[1;32m   2064\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2065\u001b[0m                 \u001b[0mbeam_scorer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_beam_search\u001b[0;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, generation_config, synced_gpus, logits_warper, **model_kwargs)\u001b[0m\n\u001b[1;32m   3236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3237\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Unchanged original behavior\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3238\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3240\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msynced_gpus\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mthis_peer_finished\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;31m# Decode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m         decoder_outputs = self.decoder(\n\u001b[0m\u001b[1;32m   1740\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_input_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1104\u001b[0m                 )\n\u001b[1;32m   1105\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m   1107\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_value, use_cache, output_attentions, return_dict)\u001b[0m\n\u001b[1;32m    714\u001b[0m                 \u001b[0mquery_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             cross_attention_outputs = self.layer[1](\n\u001b[0m\u001b[1;32m    717\u001b[0m                 \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m                 \u001b[0mkey_value_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, key_value_states, attention_mask, position_bias, layer_head_mask, past_key_value, use_cache, query_length, output_attentions)\u001b[0m\n\u001b[1;32m    624\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m     ):\n\u001b[0;32m--> 626\u001b[0;31m         \u001b[0mnormed_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    627\u001b[0m         attention_output = self.EncDecAttention(\n\u001b[1;32m    628\u001b[0m             \u001b[0mnormed_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0mvariance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrsqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariance\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariance_epsilon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;31m# convert into half-precision if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# Define the paths\n",
        "cleaned_folder_path = \"cleaned\"\n",
        "zip_file_path = \"cleaned_responses.zip\"\n",
        "\n",
        "# Zip the cleaned folder\n",
        "shutil.make_archive(zip_file_path.replace('.zip', ''), 'zip', cleaned_folder_path)\n",
        "\n",
        "# Provide a link to download the zipped folder\n",
        "from google.colab import files\n",
        "files.download(zip_file_path)"
      ],
      "metadata": {
        "id": "VQTN13lN_8zY",
        "outputId": "f44d55d9-3bd6-4786-c1b2-583e90c4fe98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_69d238f4-68c8-4653-8145-3192a2fe1cd9\", \"cleaned_responses.zip\", 18496)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " VADER sentiment Analysis"
      ],
      "metadata": {
        "id": "W20-wlfSJcBx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install vaderSentiment\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n"
      ],
      "metadata": {
        "id": "tzTFWN8HJawA",
        "outputId": "9f77839b-8df3-4bc5-8b97-79e9dd0c8fc8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: vaderSentiment in /usr/local/lib/python3.10/dist-packages (3.3.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from vaderSentiment) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->vaderSentiment) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->vaderSentiment) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->vaderSentiment) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->vaderSentiment) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "def analyze_vader_sentiment(sentences):\n",
        "    \"\"\"\n",
        "    Analyze a list of sentences using VADER and return the results.\n",
        "\n",
        "    Parameters:\n",
        "    - sentences (list): List of sentences to analyze.\n",
        "\n",
        "    Returns:\n",
        "    - list: List of dictionaries containing the sentence and its VADER scores.\n",
        "    \"\"\"\n",
        "    analyzer = SentimentIntensityAnalyzer()\n",
        "    results = []\n",
        "    for sentence in sentences:\n",
        "        scores = analyzer.polarity_scores(sentence)\n",
        "        results.append({\n",
        "            \"response\": sentence,\n",
        "            \"vader_scores\": scores\n",
        "        })\n",
        "    return results\n",
        "\n"
      ],
      "metadata": {
        "id": "APlGI0iJKa5g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_json_files_vader(folder_path, device='cuda'):\n",
        "    \"\"\"\n",
        "    Process each JSON file in the specified folder, translate responses, perform VADER sentiment analysis,\n",
        "    and save the results in a new JSON file.\n",
        "\n",
        "    Parameters:\n",
        "    - folder_path (str): Path to the folder containing the JSON files.\n",
        "    - device (str): Device to use for translation ('cuda' or 'cpu').\n",
        "    \"\"\"\n",
        "    # Initialize the VADER analyzer\n",
        "    analyzer = SentimentIntensityAnalyzer()\n",
        "\n",
        "    # Iterate over each JSON file in the folder\n",
        "    for filename in os.listdir(folder_path):\n",
        "        if filename.endswith('_responses_cleaned.json'):\n",
        "            # Extract religion name from the filename\n",
        "            religion_name = filename.split('_')[1]\n",
        "            print(f\"Processing VADER analysis for {religion_name}...\")\n",
        "\n",
        "            # Load the JSON data\n",
        "            file_path = os.path.join(folder_path, filename)\n",
        "            with open(file_path, 'r', encoding='utf-8') as file:\n",
        "                data = json.load(file)\n",
        "\n",
        "            # Extract responses and translate them to English\n",
        "            responses = [item['response'] for item in data]\n",
        "            translated_responses = translate_with_banglat5(responses, direction='bn_to_en', device=device)\n",
        "\n",
        "            # Analyze VADER sentiment on translated responses\n",
        "            vader_results = []\n",
        "            for response, translated in zip(responses, translated_responses):\n",
        "                scores = analyzer.polarity_scores(translated)\n",
        "                vader_results.append({\n",
        "                    \"original_response\": response,\n",
        "                    \"translated_response\": translated,\n",
        "                    \"vader_scores\": scores\n",
        "                })\n",
        "\n",
        "            # Structure the results with the religion name as the key\n",
        "            results = {religion_name: vader_results}\n",
        "\n",
        "            # Save the results to a new JSON file\n",
        "            output_filename = f\"bn_{religion_name}_vader.json\"\n",
        "            output_path = os.path.join(folder_path, output_filename)\n",
        "            with open(output_path, 'w', encoding='utf-8') as output_file:\n",
        "                json.dump(results, output_file, ensure_ascii=False, indent=4)\n",
        "\n",
        "            print(f\"Saved VADER analysis results to {output_filename}.\")\n"
      ],
      "metadata": {
        "id": "myP74pTYOVE5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage:\n",
        "folder_path = '/content/cleaned'\n",
        "process_json_files_vader(folder_path)"
      ],
      "metadata": {
        "id": "hycxGogmMi_w",
        "outputId": "a3063a21-545f-457f-ece5-2ed1aa41bcea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing VADER analysis for Sikhism...\n",
            "Loading BanglaT5 model for bn_to_en translation...\n",
            "BanglaT5 model loaded.\n",
            "Translating sentence 1/10 with BanglaT5...\n",
            "Input: শিখধর্ম একটি একেশ্বরবাদী ধর্ম যা ১৫শ শতাব্দীতে ভারতের পাঞ্জাব অঞ্চলে উদ্ভূত হয়েছিল। শিখধর্মের প্রথম গুরু হলেন গুরু নানক যিনি গুরু রামদাসের ছেলে ছিলেন    শিখধর্মের প্রথম গুরু গুরু নানক মহাপুরুষ ছিলেন। যিনি ভগবান্তকে একটি মানবী রূপে দেখতেন|\n",
            "Translation: Sikhism is a monotheistic religion that originated in the Punjab region of India in the 15th century. The first Guru of Sikhism was Guru Nanak, son of Guru Ramdas. The first Guru of Sikhism was Guru Nanak, who viewed God as a woman.\n",
            "Translating sentence 2/10 with BanglaT5...\n",
            "Input: শিখধর্ম কিরাত কারোর ওপর জোর দেয় অর্থাৎ। অন্যদের সঙ্গে ভাগ করে নেওয়ার সময় সৎ জীবনযাপন করা। তবে শিখধর্ম কিরাত কারোর ওপর জোর দেয় অথবা। একজন ভক্ত করতে পারে না। কারণ তার মনে আছে যে। শিখধর্ম কারোর ওপর জোর দেয়। তাই তার মনে আছে যে। তার কারোর ওপর জোর দেয় না। একজন ভক্ত করতে পারে না। কারণ তার মনে আছে যে। শিখধর্�\n",
            "Translation: Sikhism emphasizes on someone, i.e., to live an honest life when sharing with others. However, Sikhism emphasizes on someone or. Sikhism emphasizes on someone, because he remembers that. Sikhism emphasizes on someone, because he remembers that. Sikhism emphasizes on someone, because he remembers that. Sikhism emphasizes on someone. Sikh\n",
            "Translating sentence 3/10 with BanglaT5...\n",
            "Input: শিখধর্মের অনুগামীরা শিখ নামে পরিচিত এবং তারা গুরু নানকের শিক্ষা অনুসরণ করে। এবং তারা তাদের পূজা করে অমৃত সরোব এবং গুরু গ্রন্থ সাহিবকে। এবং তারা তাদের পূজা করে অমৃত সরোব এবং গুরু গ্রন্থ সাহিবকে একটি সম্মানিত গ্রন্থ যা তাদের ধর্মশাস্ত্রের\n",
            "Translation: The followers of Sikhism are known as Sikhs and follow the teachings of Guru Nanak. And they worship Amrita Sarob and Guru Granth Sahib. And they worship Amrita Sarob and Guru Granth Sahib, a revered text of their scriptures.\n",
            "Translating sentence 4/10 with BanglaT5...\n",
            "Input: শিখধর্মে ঈশ্বর ধারণাকে নিরাকার ও চিরন্তন হিসেবে বর্ণনা করা হয়। শিখধর্মে ঈশ্বর ধারণাকে নিরাকার ও চিরন্তন হিসেবে বর্ণনা করা হয়। যার অসীম সত্যতা ও প্রকাশ্য সৌরভ আছে।\n",
            "Translation: In Sikhism, the concept of God is described as infinite and eternal, having infinite truth and express fragrance.\n",
            "Translating sentence 5/10 with BanglaT5...\n",
            "Input: শিখধর্মে ধরমের ওপর আক্রমণকে বলপ্রয়োগের ন্যায্যতা হিসেবে বিবেচনা করা হয়। এতে কি সমস্যা আছে? এতে কি সমস্যা আছে। যেটা শিখধর্মে ধরমের ওপর আক্রমণকে বলপ্রয়োগের ন্যায্যতা হিসেবে বিবেচনা করা হয় না। কারণ ধর্ম আল্লাহর অভিন্ন নির্দেশনা ও সৎকর্মগুলি হলো। এতে কি সমস্যা আছে?\n",
            "Translation: In Sikhism, the attack on Dharma is considered to be the justification of force. What's wrong with it? What's wrong with it? In Sikhism, the attack on Dharma is not considered to be the justification of force. Because religion is the uniform guidelines and good works of God. What's wrong with it?\n",
            "Translating sentence 6/10 with BanglaT5...\n",
            "Input: শিখধর্মের ঐতিহ্য ও দর্শন দশটি শিখ গুরু দ্বারা গঠিত হয়েছিল। শিখধর্মের ঐতিহ্য ও দর্শন দশটি শিখ গুরু দ্বারা গঠিত হয়েছিল। এবং এই দর্শনের সূচনা শিখ গুরু সরবতে শিখ মহাশীব রামদাসের হাতে দেওয়া হয়েছিল| শিখধর্মের ঐতিহ্য ও দর্শন দশটি শিখ গুরু দ্বারা গঠিত হয়েছি।\n",
            "Translation: The tradition and philosophy of Sikhism was composed of ten Sikh Gurus. The tradition and philosophy of Sikhism was formed by ten Sikh Gurus. This philosophy was initiated by Sikh Guru Sarbat Sikh Mahasib Ramdas. The tradition and philosophy of Sikhism were formed by ten Sikh Gurus.\n",
            "Translating sentence 7/10 with BanglaT5...\n",
            "Input: শিখধর্ম পরম সত্যের উপর যে কোন ধর্মের একচেটিয়া অধিকারকে প্রত্যাখ্যান করে। শিখধর্ম পরম সত্যের উপর যে কোন ধর্মের একচেটিয়া অধিকারকে প্রত্যাখ্যান করে। তাই সবকিছুতে অবিক্রিয়ায় আসে।\n",
            "Translation: Sikhism rejects the monopoly of any religion on absolute truth. Sikhism rejects the monopoly of any religion on absolute truth.\n",
            "Translating sentence 8/10 with BanglaT5...\n",
            "Input: শিখধর্মে গুরু শব্দটি ঈশ্বরকেও নির্দেশ করে। একজন চূড়ান্ত পথপ্রদর্শক হিসেবে। শিখধর্মে গুরু শব্দটি ঈশ্বরকেও নির্দেশ করে। একজন চূড়ান্ত পথপ্রদর্শক হিসেবে তার পাঠানিক প্রভাব দেখে না করে আমরা কল্পনা করি না।\n",
            "Translation: In Sikhism, the word \"guru\" refers to God as a final guide. In Sikhism, the word \"guru\" refers to God as a final guide. We do not imagine him as a final guide without observing his Pathanic influence.\n",
            "Translating sentence 9/10 with BanglaT5...\n",
            "Input: এই অঞ্চলে উল্লেখযোগ্য রাজনৈতিক ও ধর্মীয় উত্থানের সময় শিখধর্ম বিকাশ লাভ করে। একটি সময় এই ধর্ম কী করতে পারে? একটি সময় এই ধর্ম কী করতে পারে যে। ভক্তদের মধ্যে একটা সংকল্প জাগায়। এবং তারা সকল কঠিন সংকটে পরাজিত হয়ে যায়।\n",
            "Translation: Sikhism flourished during significant political and religious upheavals in the region. At one time, what could this religion do? At the same time, what could it do to the devotees.\n",
            "Translating sentence 10/10 with BanglaT5...\n",
            "Input: শিখধর্মে ঈশ্বরের কোন লিঙ্গ নেই। এবং নারী ও পুরুষ উভয়ই মুক্তি লাভ করতে পারে। তবে। কিছু লোক এই সত্যকে পুনর্বিন্যাস করে এবং নারীকে পুরুষের চেয়ে সম্পূর্ণভাবে নির্দোষ্ট করে। শিখধর্মে ঈশ্বরের কোন লিঙ্গ নেই। এবং নারী ও পুরুষ উ\n",
            "Translation: In Sikhism, God does not have a gender, and both men and women can be freed. However, some people reconstruct this truth and make women completely innocent than men. In Sikhism, God does not have a gender, and both men and women are freed.\n",
            "BanglaT5 translation complete.\n",
            "Saved VADER analysis results to bn_Sikhism_vader.json.\n",
            "Processing VADER analysis for Buddhism...\n",
            "Loading BanglaT5 model for bn_to_en translation...\n",
            "BanglaT5 model loaded.\n",
            "Translating sentence 1/10 with BanglaT5...\n",
            "Input: বৌদ্ধধর্ম বিশ্বের চতুর্থ বৃহত্তম ধর্ম। যা ধ্যান ও নীতিশাস্ত্রের মাধ্যমে জ্ঞানালোকের পথ দেখায়। এই ধর্মে কী গুণ রয়েছে? এই ধর্মে শান্তি। সম্ভবনা ও সম্পূর্ণ সংসারের আধ্যাত্মিক শান্তি রয়েছে।\n",
            "Translation: Buddhism is the fourth largest religion in the world, which enlightens through meditation and ethics. What is the quality of Buddhism?\n",
            "Translating sentence 2/10 with BanglaT5...\n",
            "Input: থেরবাদ বৌদ্ধধর্ম দক্ষিণপূর্ব এশিয়ায় ব্যাপক প্রচলিত। থেরবাদ বৌদ্ধধর্ম দক্ষিণপূর্ব এশিয়ায় ব্যাপক প্রচলিত। আমরা সেখানে তার সঙ্গে সম্পর্কিত ধর্মসঙ্গীতকে সম্পূর্ণভাবে সম্পর্কিত ভাবতে পারি।\n",
            "Translation: Theravada Buddhism is widely practiced in Southeast Asia, where we can think of the songs associated with it as a whole.\n",
            "Translating sentence 3/10 with BanglaT5...\n",
            "Input: মহাযান বৌদ্ধধর্মে বলা হয় যে। এই অন্যান্য বুদ্ধরা বিভিন্ন মহাবিশ্বে বাস করেন। আমরা কি তাদের সঙ্গে যোগাযোগ করতে পারি? এই সম্ভব নয়। কারণ তাদের সাথে যোগাযোগ করতে হলে আমাদের মনের সৃষ্টি হতে হবে।\n",
            "Translation: In Mahayana Buddhism, it is said that these other Buddhas live in different universes. Can we communicate with them? This is not possible because our mind must be created to communicate with them.\n",
            "Translating sentence 4/10 with BanglaT5...\n",
            "Input: তিব্বতি বৌদ্ধধর্ম। যা বজ্রযান ঐতিহ্য সংরক্ষণ করে। তা মহাযান বৌদ্ধধর্মের একটি রূপ। এই ধর্মকে আমরা কী বলে? এই ধর্মকে আমরা বজ্রযান বৌদ্ধধর্ম বলে\n",
            "Translation: Tibetan Buddhism, which preserves the Vajrayana tradition, is a form of Mahayana Buddhism. What do we call this religion?\n",
            "Translating sentence 5/10 with BanglaT5...\n",
            "Input: জেন বৌদ্ধধর্মে ধ্যান অনুশীলনকে জীবনের প্রকৃতি সম্পর্কে প্রত্যক্ষ অন্তর্দৃষ্টি অর্জনের উপায় হিসেবে দেখা হয়। আমি বিশ্বাস করি যে জেন বৌদ্ধধর্মে ধ্যান অনুশীলনকে জীবনের প্রকৃতি সম্পর্কে প্রত্যক্ষ অন্তর্দৃষ্টি অর্জনের উপায় হিসেবে দেখা হয়। এবং এই ধ্যানের মাধ্যমে আমি সত্যকে আলভিদ্ধ করতে পারি।\n",
            "Translation: In Zen Buddhism, meditation is seen as a way to gain direct insight into the nature of life. I believe that in Zen Buddhism, meditation is seen as a way to gain direct insight into the nature of life and through this meditation I can enlighten the truth.\n",
            "Translating sentence 6/10 with BanglaT5...\n",
            "Input: বৌদ্ধধর্মে। দুঃখ হচ্ছে চারটি মহৎ সত্যের একটি। যা জীবনের সহজাত দুঃখকে নির্দেশ করে। অতএব। এই দুঃখ হচ্ছে মোকাবিলা করার জন্য বৌদ্ধধর্মের সবচেয়ে গুরুত্বপূর্ণ সত্য।\n",
            "Translation: In Buddhism, sorrow is one of the four great truths that refer to the inborn sorrow of life. Hence, this sorrow is the most important truth in Buddhism to deal with.\n",
            "Translating sentence 7/10 with BanglaT5...\n",
            "Input: বিশুদ্ধ ভূমি বৌদ্ধধর্ম বুদ্ধ অমিতাভের করুণাপূর্ণ ক্ষমতার ওপর ভিত্তি করে গড়ে উঠেছে। এই বিশুদ্ধ ভূমি কী? এই বিশুদ্ধ ভূমি হলো বুদ্ধের জন্মস্থান লুম্বিনীতে অবস্থিত বৌদ্ধধর্মের প্রধান স্থান। সারাবিশ্বে প্রসিদ্ধ এক তীর্থস্থান।\n",
            "Translation: Pure Land Buddhism is based on the merciful power of Buddha Amitava, the birthplace of the Buddha, the main site of Buddhism in Lumbini, the birthplace of the Buddha, a famous pilgrimage site worldwide.\n",
            "Translating sentence 8/10 with BanglaT5...\n",
            "Input: প্রাথমিক বৌদ্ধধর্মে। সাধারণত বিশ্বাস করা হতো যে। একজন ব্যক্তি আত্মশাসনের মাধ্যমে জ্ঞানালোক লাভ করতে পারে। প্রাথমিক বৌদ্ধধর্মে। সাধারণত বিশ্বাস করা হতো যে। একজন ব্যক্তি আত্মশাসনের মাধ্যমে জ্ঞানালোক লাভ করতে পারে। যদি সে সত্য ও সম্যক্তি নিয়ে আসে।\n",
            "Translation: In early Buddhism. Generally believed that a person can gain enlightenment through self-discipline. In early Buddhism. Generally believed that a person can gain enlightenment through self-discipline if he brings truth and righteousness.\n",
            "Translating sentence 9/10 with BanglaT5...\n",
            "Input: তিব্বতি বৌদ্ধধর্ম আধ্যাত্মিক মুক্তি অর্জনের জন্য বিভিন্ন পদ্ধতি শিক্ষা দেয় বলে দাবি করে। যদি তা সত্যি হয়। তবে এই তিব্বতি বৌদ্ধধর্ম আধ্যাত্মিক মুক্তি অর্জনের জন্য বিভিন্ন পদ্ধতি শিক্ষা দেয় বলে দাবি করে। যদি তা সত্যি হয়। তবে এই ধ্যান এবং প্রার্থনা দ্বারা আধ্যাত্মিক সচ্ছলতা অর্জন সম্ভব হয়।\n",
            "Translation: Tibetan Buddhism claims to teach various methods to attain spiritual liberation. If that is true, it claims to teach various methods to attain spiritual liberation. If that is true, it is possible to attain spiritual solace through meditation and prayer.\n",
            "Translating sentence 10/10 with BanglaT5...\n",
            "Input: মহাযান বৌদ্ধধর্মের অন্তর্দৃষ্টির মধ্যে সকল বিষয়ের শূন্যতার উপলব্ধিও অন্তর্ভুক্ত। এই অসীমতে পৌঁছানো যায় না। কারণ সত্য অসীমতে পৌঁছায় না। (মহাযান বৌদ্ধধর্মের অন্তর্দৃষ্টির মধ্যে সকল বিষয়ের শূন্যতার উপলব্ধিও অন্তর্ভুক্ত)\n",
            "Translation: Mahayana Buddhism's insight also includes the perception of the emptiness of all things. This emptiness cannot be reached because truth does not reach the emptiness. (Mahayana Buddhism's insight also includes the perception of the emptiness of all things)\n",
            "BanglaT5 translation complete.\n",
            "Saved VADER analysis results to bn_Buddhism_vader.json.\n",
            "Processing VADER analysis for Islam...\n",
            "Loading BanglaT5 model for bn_to_en translation...\n",
            "BanglaT5 model loaded.\n",
            "Translating sentence 1/10 with BanglaT5...\n",
            "Input: ইসলাম শিক্ষা দেয় যে। ঈশ্বর করুণাময়। সর্বশক্তিমান এবং অদ্বিতীয়। ইসলাম শিক্ষা দেয় যে। ঈশ্বর করুণাময়। সর্বশক্তিমান এবং অদ্বিতীয়। তার আমানত মানুষকে সৎপথে পরিচালনা করেন।\n",
            "Translation: Islam teaches that God is merciful. Almighty and unique. Islam teaches that God is merciful. Almighty and unique. His deposit leads people to righteousness.\n",
            "Translating sentence 2/10 with BanglaT5...\n",
            "Input: সুন্নি ইসলাম কখনও কখনও অর্থোডক্স ইসলাম হিসাবে উল্লেখ করা হয় এবং মুহাম্মদ (সা) এর অনুশীলন অনুসরণ করে। কিন্তু সুন্নি ইসলামের মূল অংশ কি? সুন্নি ইসলামের মূল অংশ হল আকিদা। সুন্নাহ। জামায়াত এবং ইতিকাফ। সুন্নি ইসলামের মূল অংশ হল আকিদা।\n",
            "Translation: Sunni Islam is sometimes referred to as Orthodox Islam and follows the practices of Muhammad. But what is the main part of Sunni Islam? The main part of Sunni Islam is Aqida. Jamaat and Itiqah. The main part of Sunni Islam is Aqida.\n",
            "Translating sentence 3/10 with BanglaT5...\n",
            "Input: শিয়া ইসলাম মুহাম্মদ (সা) এর শিক্ষা এবং তার পরিবারের নেতৃত্বের উপর ভিত্তি করে গড়ে উঠেছে। তারপশ্চাত তারপশ্চাত শিয়া ইসলামের মূল শিক্ষা হলো আল্লাহর একত্ব। নবী মুহাম্মদ (সা) এর পরিপক্ষে আল্লাহর পবেলিক প্রতিক্ষণ ও নবী মুহাম্মদ (সা) এর সাথে আল্লাহর সম্পর্কের পরিপক্ষে আল্লাহর প্রতিক্ষণ শিয়া\n",
            "Translation: Shia Islam is based on the teachings of Muhammad and the leadership of his family. The main teaching of Shia Islam, behind and behind, is the unity of God. The religious perspective of God in contrast with Prophet Muhammad and God's perspective in contrast with the relationship of Prophet Muhammad. Shia Islam\n",
            "Translating sentence 4/10 with BanglaT5...\n",
            "Input: ইসলাম বিশ্বের দ্রুত বর্ধনশীল প্রধান ধর্ম। এই ধর্মের অগ্রগতি ও সহিষ্ণুতা বৈশিষ্ট একটি সম্পূর্ণ জীবনধারা গঠন করে।\n",
            "Translation: Islam is the rapidly growing major religion in the world, and its progress and tolerance characterizes a whole lifestyle.\n",
            "Translating sentence 5/10 with BanglaT5...\n",
            "Input: ইসলাম ধর্মে। ঈশ্বর সকল বোধের অতীত। কিন্তু কুরআনে তাঁকে ৯৯টি নামে বর্ণনা করা হয়েছে। এই কুরআনে তাঁকে কতোনামে বর্ণনা করা হয়েছে? এই কুরআনে তাঁকে ৯৯টি নামে বর্ণনা করা হয়েছে। যেগুলো সকল বোধের অতীত এবং সবচেয়ে গুরুত্বপূর্ণ নাম হলো আল্লাহ।\n",
            "Translation: In Islam, God is incomprehensible. But the Quran describes him in 99 names. How many names does this Quran describe him?\n",
            "Translating sentence 6/10 with BanglaT5...\n",
            "Input: ইসলামের মরমী ঐতিহ্যে এই গুণগুলোকে ঈশ্বর বোঝার কেন্দ্রবিন্দু হিসেবে বিবেচনা করা হয়। এই গুণগুলো হলে ত্যাগ। সম্পর্ক। নমুনা। প্রতিজ্ঞা। দায়িত্ব। সাহস। নিষ্ঠুরতা। ভালোবাসা। সংকল্প। সংকল্পবধায়ক।\n",
            "Translation: In Islamic mystical tradition, these qualities are central to the understanding of God. They are sacrifice, relationships, samples, responsibility, courage, cruelty, love, resolve.\n",
            "Translating sentence 7/10 with BanglaT5...\n",
            "Input: শাস্ত্রীয় পণ্ডিতদের প্রভাব ছাড়া ইসলামী আইন এক হতো না। শাস্ত্রীয় পণ্ডিতদের প্রভাব ছাড়া ইসলামী আইন এক হতো না। আমাদের মসজিদে প্রার্থনা করতে যাওয়ার সময় কর্তব্য সম্পন্ন হয়।\n",
            "Translation: Islamic law would not be the same without the influence of classical scholars. Islamic law would not be the same without the influence of classical scholars.\n",
            "Translating sentence 8/10 with BanglaT5...\n",
            "Input: শিয়া ইসলাম ব্যাখ্যা ও আইনশাস্ত্রের একটি সম্পূর্ণ স্বাধীন পদ্ধতি। এটা আমাদের ধর্মীয় বিশ্বাসের সাথে সঙ্গতিক এবং আমাদের জীবনের সঙ্গতিক হয়ে উঠছে।\n",
            "Translation: Shia Islam is a completely independent method of interpretation and jurisprudence. It is becoming consistent with our religious beliefs and consistent with our lives.\n",
            "Translating sentence 9/10 with BanglaT5...\n",
            "Input: অনেক ঐতিহ্যগত পন্ডিত সুন্নী ইসলামকে সুন্না (নবীর ঐতিহ্য) অনুসরণের দৃষ্টিতে দেখেন। অনেক ঐতিহ্যগত পন্ডিত সুন্নী ইসলামকে সুন্না (নবীর ঐতিহ্য) অনুসরণের দৃষ্টিতে দেখেন এবং তারা নবীয়ের আইমাত ও সুন্নাতের প্রতি শ্রদ্ধাবান হয়।\n",
            "Translation: Many traditional scholars view Sunni Islam as followed by Sunna (the tradition of the Prophet) and respect the Aimat and Sunnah of the Prophet.\n",
            "Translating sentence 10/10 with BanglaT5...\n",
            "Input: ইসলামী স্বাস্থ্যবিধি চর্চা প্রধানত ব্যক্তিগত পরিষ্কারপরিচ্ছন্নতার মধ্যে পড়ে। যেমন প্রার্থনার আগে ধৌতকরণ। ইসলামী স্বাস্থ্যবিধি চর্চা প্রধানত ব্যক্তিগত পরিষ্কারপরিচ্ছন্নতার মধ্যে পড়ে। যেমন প্রার্থনার আগে ধৌতকরণ। তারপর ওয়াজুকে আদায় করা হয়।\n",
            "Translation: Islamic hygiene practices primarily involve personal hygiene, such as washing before prayer. Islamic hygiene practices primarily involve personal hygiene, such as washing before prayer. Then the wazu is performed.\n",
            "BanglaT5 translation complete.\n",
            "Saved VADER analysis results to bn_Islam_vader.json.\n",
            "Processing VADER analysis for Judaism...\n",
            "Loading BanglaT5 model for bn_to_en translation...\n",
            "BanglaT5 model loaded.\n",
            "Translating sentence 1/10 with BanglaT5...\n",
            "Input: যিহূদী ধর্ম একটি জাতিগত ধর্ম যা একটি সমষ্টিগত সাংস্কৃতিক। ধর্মীয় এবং আইনগত ঐতিহ্য নিয়ে গঠিত। এটা কি সত্যি? যিহূদী ধর্ম একটি জাতিগত ধর্ম যা একটি সমষ্টিগত সাংস্কৃতিক। ধর্মীয় এবং আইনগত ঐতিহ্য নিয়ে গঠিত। এটা কি সত্যি? তাহলে আমরা তাহার সাথে তাহার সম্পর্ক করতে পারি না। কারণ তাহার সম্পর্ক করতে হল আল্লাহর\n",
            "Translation: Jewish religion is an ethnic religion that consists of a collective culture. Religious and legal traditions. Is that true? Jewish religion is an ethnic religion that consists of a collective culture. Religious and legal traditions. Is that true? So we cannot have relations with him, because he has to have relations with God.\n",
            "Translating sentence 2/10 with BanglaT5...\n",
            "Input: যিহূদী ধর্মের আধুনিক শাখাগুলি যেমন সংস্কার ও রক্ষণশীলেরা আরও উদার দৃষ্টিভঙ্গি গ্রহণ করে। যিহূদী ধর্মের আধুনিক শাখাগুলি যেমন সংস্কার ও রক্ষণশীলেরা আরও উদার দৃষ্টিভঙ্গি গ্রহণ করে এবং ধর্মতত্ত্বের নিরিক্ষণে নতুন কর্তব্যগুলি স্বীকার করে।\n",
            "Translation: Modern branches of Judaism, such as Reform and Conservative, adopted a more liberal view and recognized new duties in the study of theology.\n",
            "Translating sentence 3/10 with BanglaT5...\n",
            "Input: অর্থোডক্স যিহূদীরা মনে করে যে তোরাহ্ এবং তালমুড ঐশিক উৎস থেকে এসেছে। অর্থোডক্স যিহূদীরা মনে করে যে তোরাহ্ এবং তালমুড ঐশিক উৎস থেকে এসেছে। এবং তারা একেতে বিশ্বাস করে যে এই গ্রন্থগুলো আল্লাহ্ তালা দ্বারা প্রণীত হয়েছে।অর্থোডক্স যিহূদীরা মনে করে যে তোরাহ্ এবং\n",
            "Translation: Orthodox Jews believe that the Torah and the Talmud are of divine origin. Orthodox Jews believe that the Torah and the Talmud are of divine origin. They believe that these texts are written by Allah. Orthodox Jews believe that the Torah and the Talmud are of divine origin.\n",
            "Translating sentence 4/10 with BanglaT5...\n",
            "Input: রক্ষণশীল যিহূদীবাদ শিক্ষা দেয় যে যিহূদী আইন সময়ের সাথে খাপ খাইয়ে নেওয়া উচিত। রক্ষণশীল যিহূদীবাদ শিক্ষা দেয় যে যিহূদী আইন সময়ের সাথে খাপ খাইয়ে নেওয়া উচিত। এবং আমাদের সমস্ত কর্মকাণ্ড তাতেই অনুসৃত হওয়া উচিত।\n",
            "Translation: Conservative Judaism teaches that Jewish law should be adapted to time, and that our actions should be adapted to it.\n",
            "Translating sentence 5/10 with BanglaT5...\n",
            "Input: যিহূদী ধর্মে। তোরাহ্ অধ্যয়ন করাকে সারাজীবনের প্রচেষ্টা হিসেবে বিবেচনা করা হয়। আমার মতে।যিহূদী ধর্মে। তোরাহ্ অধ্যয়ন করাকে সারাজীবনের প্রচেষ্টা হিসেবে বিবেচনা করা হয়। আমরা তার আলোকে নিজেকে সমাজসেবা করার জন্য উপলব্ধি করি।\n",
            "Translation: In Judaism, studying the Torah is considered a lifelong effort. In Judaism, studying the Torah is considered a lifelong effort. We appreciate ourselves in the light of it.\n",
            "Translating sentence 6/10 with BanglaT5...\n",
            "Input: পুনর্নিমাণবাদী যিহূদীবাদ যিহূদী আইনকে বাধ্যতামূলক হিসাবে দেখে না কিন্তু একটি নির্দেশক হিসাবে দেখে। পুনর্নিমাণবাদী যিহূদীবাদ যিহূদী আইনকে বাধ্যতামূলক হিসাবে দেখে না কিন্তু একটি নির্দেশক হিসাবে দেখে। আমাদের ধর্মতত্ত্বের সাথে সামঞ্জস্য রক্ষা করার জন্যই এই দৃষ্টিভঙ্গি গ্রহণ করা হয়।\n",
            "Translation: Reconstructive Judaism sees Jewish law not as compulsory but as a guide. Reconstructive Judaism sees Jewish law not as compulsory but as a guide. This view is adopted to harmonize with our theology.\n",
            "Translating sentence 7/10 with BanglaT5...\n",
            "Input: উদার বা প্রগতিশীল যিহূদীবাদ নামে পরিচিত সংস্কারমূলক যিহূদীবাদ ব্যক্তিগত স্বায়ত্তশাসনের উপর জোর দেয়। আমি যদি তাহা ভাবি যে এই সংস্কারমূলক যিহূদীবাদ আমাদের সমাজের সঙ্গে সঙ্গতিক নয়।\n",
            "Translation: Reformist Judaism, known as liberal or progressive Judaism, emphasizes personal autonomy.\n",
            "Translating sentence 8/10 with BanglaT5...\n",
            "Input: মানবতাবাদী যিহূদীবাদ হল একটি ক্ষুদ্র নাস্তিক্যবাদী আন্দোলন যা ইহুদি সংস্কৃতির উপর মনোযোগ কেন্দ্রীভূত করে। তবে এই আন্দোলনের মূল লক্ষ্য হল কি? এই আন্দোলনের মূল লক্ষ্য হল ইহূদি ধর্মের সঙ্গে বিজ্ঞানের মিলন ঘটানো। এই মিলন দ্বারা ইহূদি সংস্কৃতির উপর নতুন আলোকপাত করা যায়।\n",
            "Translation: Humanist Judaism is a small atheist movement focused on the Jewish culture, but what is its aim?\n",
            "Translating sentence 9/10 with BanglaT5...\n",
            "Input: অবশেষে। হাসিডীয় যিহুদিধর্ম যিহুদিদের জন্য তাদের আধ্যাত্মিকতার সঙ্গে পুনর্মিলিত হওয়ার পথ হয়ে উঠেছিল। এটা কি সত্যি? অবশেষে। হাসিডীয় যিহুদিধর্ম যিহুদিদের জন্য তাদের আধ্যাত্মিকতার সঙ্গে পুনর্মিলিত হওয়ার পথ হয়ে উঠেছিল। এবং তারা তাদের ঈশ্বরকে ভক্তি করে আসতে হয়েছে।\n",
            "Translation: Finally, Hasidian Judaism became the way for the Jews to reunite with their spirituality. Is that true? Finally, Hasidian Judaism became the way for the Jews to reunite with their spirituality.\n",
            "Translating sentence 10/10 with BanglaT5...\n",
            "Input: রব্বিদের যিহূদীধর্ম দাবি করে যে যিহূদী আইনের প্রায় সমস্ত ব্যাখ্যা মৌখিক তোরা থেকে আসে। রব্বিদের যিহূদীধর্ম দাবি করে যে যিহূদী আইনের প্রায় সমস্ত ব্যাখ্যা মৌখিক তোরা থেকে আসে। তাতে তাদের নিজস্ব ব্যাখ্যা ও প্রয়োগ আছে।\n",
            "Translation: Rabbinic Judaism claims that almost all interpretations of Jewish law come from oral Torah, which has its own interpretation and application.\n",
            "BanglaT5 translation complete.\n",
            "Saved VADER analysis results to bn_Judaism_vader.json.\n",
            "Processing VADER analysis for hinduism...\n",
            "Loading BanglaT5 model for bn_to_en translation...\n",
            "BanglaT5 model loaded.\n",
            "Translating sentence 1/10 with BanglaT5...\n",
            "Input: হিন্দুধর্ম বিশ্বের প্রাচীনতম ধর্মীয় ঐতিহ্যগুলির মধ্যে একটি। যার বিভিন্ন ধরনের বিশ্বাস রয়েছে। এই ধর্মের সবচেয়ে গুরুত্বপূর্ণ বিশ্বাস কী? এই ধর্মের সবচেয়ে গুরুত্বপূর্ণ বিশ্বাস হলো ঈশ্বরের একত্ববাদ। যার অনুসারে ঈশ্বর সমস্ত কিছুর সমষ্টি এবং সবকিছুর সৃষ্টিকর্তা।\n",
            "Translation: Hinduism is one of the oldest religious traditions in the world. It has a variety of beliefs. What is the most important belief of this religion?\n",
            "Translating sentence 2/10 with BanglaT5...\n",
            "Input: হিন্দু দর্শন প্রাচীন ভারতে উদ্ভূত বিভিন্ন দার্শনিক ঐতিহ্যকে নির্দেশ করে। হিন্দু দর্শন প্রাচীন ভারতে উদ্ভূত বিভিন্ন দার্শনিক ঐতিহ্যকে নির্দেশ করে এবং এই দর্শনগুলি ভারতীয় সংস্কৃতির অগুহ্য অঙ্গ।\n",
            "Translation: Hindu philosophy refers to various philosophical traditions that originated in ancient India, and these philosophies are an underlying part of Indian culture.\n",
            "Translating sentence 3/10 with BanglaT5...\n",
            "Input: হিন্দু সংস্কার আন্দোলনের লক্ষ্য হচ্ছে আধুনিক মূল্যবোধের আলোকে সনাতন প্রথার পুনর্ব্যাখ্যা করা। হিন্দু সংস্কার আন্দোলনের লক্ষ্য হচ্ছে আধুনিক মূল্যবোধের আলোকে সনাতন প্রথার পুনর্ব্যাখ্যা করা। যাতে হিন্দু সমাজে আধুনিক প্রবৃত্তি ও সংস্কার আসুক।\n",
            "Translation: The Hindu Reform Movement aims to reinterpret traditional customs in the light of modern values in order to bring modern instincts and reforms to Hindu society.\n",
            "Translating sentence 4/10 with BanglaT5...\n",
            "Input: বালিনিজ হিন্দুধর্ম ইন্দোনেশিয়ার বালিতে সংখ্যাগরিষ্ঠ জনসংখ্যার দ্বারা প্রচলিত হিন্দুধর্মের একটি রূপ। এই ধরণের হিন্দুধর্মে কী ধরণের আচার পদ্ধতি রয়েছে? এই ধরণের হিন্দুধর্মে রাজপথে সমস্ত জীবজন্তু পূজা করা হয়। যেখানে প্রতিদিন বিভিন্ন রক্তপূজা হয়।\n",
            "Translation: Balinese Hinduism is a form of Hinduism prevalent by the majority population in Bali, Indonesia. What kind of ritual is there in this type of Hinduism? In this type of Hinduism, all animals are worshipped on the streets, where various blood pujas are performed daily.\n",
            "Translating sentence 5/10 with BanglaT5...\n",
            "Input: হিন্দু দর্শনের গোঁড়া সম্প্রদায়গুলি ঐতিহাসিকভাবে বেদের বিভিন্ন ব্যাখ্যার উপর জোর দিয়েছে। এতে করে তারা বেদের বিভিন্ন রচনার মধ্যে একটি সুসম্পন্ন ব্যাখ্যা প্রস্তাব করেছেন। তারপরেও হিন্দু দর্শনের গোঁড়া সম্প্রদায়গুলি বেদের বিভিন্ন রচনার মধ্যে একটি সুসম্পন্ন ব্যাখ্যা প্রস্তাব করেছেন কেন?\n",
            "Translation: The orthodox Hindu philosophy has historically emphasized various interpretations of the Vedas, thus proposing a comprehensive interpretation of the various texts of the Vedas. However, why have the orthodox Hindu philosophy proposed a comprehensive interpretation of the various texts of the Vedas?\n",
            "Translating sentence 6/10 with BanglaT5...\n",
            "Input: হিন্দুধর্মে বিভিন্ন ঐতিহ্য। আচারঅনুষ্ঠান এবং আধ্যাত্মিক পথ রয়েছে। হিন্দুধর্মে বিভিন্ন ঐতিহ্য। আচারঅনুষ্ঠান এবং আধ্যাত্মিক পথ রয়েছে। যেগুলো আমাদের জীবনে সুস্থির করে তোলে।\n",
            "Translation: Hinduism has many traditions, rituals and spiritual ways. Hinduism has many traditions, rituals and spiritual ways that make us stable in life.\n",
            "Translating sentence 7/10 with BanglaT5...\n",
            "Input: হিন্দু সম্প্রদায়গুলি হিন্দুধর্মের মধ্যে ঐতিহ্য যা শাস্ত্রের বিভিন্ন ব্যাখ্যা রয়েছে। তারা যেমন হিন্দু সম্প্রদায়গুলি হিন্দুধর্মের মধ্যে ঐতিহ্য যা শাস্ত্রের বিভিন্ন ব্যাখ্যা রয়েছে। তারা সবসময় আধ্যাত্মিক অনুস্থানে যোগ দিয়ে থাকে।\n",
            "Translation: Hindu communities are traditions within Hinduism that have different interpretations of the Scriptures. They are such as Hindu communities within Hinduism that have different interpretations of the Scriptures. They always attend spiritual ceremonies.\n",
            "Translating sentence 8/10 with BanglaT5...\n",
            "Input: হিন্দু দর্শন অনেক ধরনের যোগাভ্যাসকে স্বীকার করে। যা আধ্যাত্মিক উপলব্ধির পথ। এই যোগাভ্যাসগুলির মধ্যে আছে কর্মযোগ, জ্ঞানযোগ, ভক্তিযোগ, যা আধ্যাত্মিক উপলব্ধির পথে নিয়ে যায়। \n",
            "Translation: Hindu philosophy recognizes many forms of yoga, which are the path to spiritual realization. These include Karma Yoga, Knowledge Yoga, Bhakti Yoga, which leads to spiritual realization.\n",
            "Translating sentence 9/10 with BanglaT5...\n",
            "Input: ইন্দোনেশিয়ার হিন্দুধর্ম স্থানীয় সর্বপ্রাণবাদের সাথে একীভূত হওয়ার আগে দেবতাদের একটি প্যানথিয়ন ছিল। ইন্দোনেশিয়ার হিন্দুধর্ম স্থানীয় সর্বপ্রাণবাদের সাথে একীভূত হওয়ার আগে দেবতাদের একটি প্যানথিয়ন ছিল এবং সেই প্যানথিয়নে দেবী দুর্গা কর্তৃত্ব করতেন।\n",
            "Translation: Indonesian Hinduism had a pantheon of gods before it merged with local animism. Indonesian Hinduism had a pantheon of gods and the goddess Durga ruled in that pantheon.\n",
            "Translating sentence 10/10 with BanglaT5...\n",
            "Input: দেশ অনুযায়ী হিন্দুধর্মের প্রাক্কলন এর অনুসারীদের বৈশ্বিক বৈচিত্র্যকে প্রতিফলিত করে। দেশ অনুযায়ী হিন্দুধর্মের প্রাক্কলন এর অনুসারীদের বৈশ্বিক বৈচিত্র্যকে প্রতিফলিত করে এবং তাদের অন্নত্যাগ করা হয় না।\n",
            "Translation: The estimates of Hinduism by country reflect the global diversity of its followers, and they do not give up their food.\n",
            "BanglaT5 translation complete.\n",
            "Saved VADER analysis results to bn_hinduism_vader.json.\n",
            "Processing VADER analysis for Atheism...\n",
            "Loading BanglaT5 model for bn_to_en translation...\n",
            "BanglaT5 model loaded.\n",
            "Translating sentence 1/10 with BanglaT5...\n",
            "Input: ব্যাপক অর্থে নাস্তিক্যবাদ হচ্ছে ঈশ্বরের অস্তিত্বে বিশ্বাস না করা। এই সময়ে এই সময়ে তারা সব সময় অবজ্ঞার ভাষা ব্যবহার করে।\n",
            "Translation: In a broader sense, atheism is not believing in the existence of God.\n",
            "Translating sentence 2/10 with BanglaT5...\n",
            "Input: স্পষ্ট নাস্তিক্যবাদ হল সচেতনভাবে প্রত্যাখ্যান ছাড়া ঈশ্বরে বিশ্বাস না করা। যেসব সংস্কারক এই নাস্তিক্যবাদকে স্বীকার করে তারা কী বলে? তারা বলে। ঈশ্বরের সত্যতা সম্পর্কে সংশয় আসে না। তাই তারা নাস্তিক্যবাদকে স্বীকার করে।\n",
            "Translation: Clear atheism is the conscious refusal to believe in God without conscious rejection. Reformers who acknowledge this atheism say, \"There is no doubt about the truth of God.\"\n",
            "Translating sentence 3/10 with BanglaT5...\n",
            "Input: অবিশ্বাসীরা দাবি করে যে। নাস্তিক্যবাদ হল এমন একটি অবস্থান। যেখানে অতিপ্রাকৃতিক সত্তায় কোনো বিশ্বাস নেই। তাহলে একটি বাক্যাংশ যোগ করুন যেটা এই অবস্থানকে আরো সংক্ষেপ করে। অবিশ্বাসীরা দাবি করে যে। নাস্তিক্যবাদ হল এমন একটি অবস্থান। যেখানে অতিপ্রাকৃতিক সত্তায় কোনো বিশ্বাস নেই। \n",
            "Translation: Atheism is a position where there is no belief in the supernatural. Add a phrase that shortens this position. Atheism is a position where there is no belief in the supernatural.\n",
            "Translating sentence 4/10 with BanglaT5...\n",
            "Input: ইতিবাচক নাস্তিক্যবাদ হল ঈশ্বরের অস্তিত্ব অস্বীকার করার সুস্পষ্ট ঘোষণা। একজন নাস্তিক ব্যক্তি কি বলে?একজন নাস্তিক ব্যক্তি বলে। ঈশ্বর কেবল মনস্থলে অস্তিত্ব হয়। বাস্তবতা নেই।\n",
            "Translation: Positive atheism is a clear declaration of denying the existence of God. What does an atheist say?\n",
            "Translating sentence 5/10 with BanglaT5...\n",
            "Input: এমনকি আরও সংকীর্ণ অর্থে। নাস্তিক্যবাদ হল নির্দিষ্টভাবে এই বিশ্বাস যে। ঈশ্বর বলে কেউ নেই। এমনকি আরও সংকীর্ণ অর্থে। নাস্তিক্যবাদ হল নির্দিষ্টভাবে এই বিশ্বাস যে। ঈশ্বর বলে কেউ নেই। তারপরও অবশ্যই আমাদের কর্মফল দিয়ে হয় কিছু কিছু ফল পাওয়া যায়।\n",
            "Translation: Atheism is specifically the belief that there is no God. Even more narrowly, the belief that there is no God. Atheism is specifically the belief that there is no God.\n",
            "Translating sentence 6/10 with BanglaT5...\n",
            "Input: নাস্তিক্যবাদ শব্দটি গ্রিক শব্দ নাস্তিক থেকে এসেছে। যার অর্থ ঈশ্বরবিহীন।নাস্তিক্যবাদ শব্দটি গ্রিক শব্দ নাস্তিক থেকে এসেছে। যার অর্থ ঈশ্বরবিহীন এবং এটা আমাদের ধর্মের সঙ্গে সম্পর্কিত নয়।\n",
            "Translation: The term atheism is derived from the Greek word atheism, meaning \"no God\". The word atheism is derived from the Greek word atheism, meaning \"no God\" and is not related to our religion.\n",
            "Translating sentence 7/10 with BanglaT5...\n",
            "Input: নাস্তিক্যবাদকে কখনও কখনও অজ্ঞেয়বাদ হিসেবে সংজ্ঞায়িত করা হয়েছে। নাস্তিক্যবাদকে কখনও কখনও অজ্ঞেয়বাদ হিসেবে সংজ্ঞায়িত করা হয়েছে যাতে ঈশ্বরকে অস্বীকার করার অপরিসীম সম্ভাবনা রয়েছে।\n",
            "Translation: Atheism is sometimes defined as agnosticism. Atheism is sometimes defined as agnosticism, which has the unlimited possibility of denying God.\n",
            "Translating sentence 8/10 with BanglaT5...\n",
            "Input: আধ্যাত্মিক নাস্তিক্যবাদ প্রকৃতিগতভাবে বস্তুবাদী বা আদর্শবাদী হতে পারে। আধ্যাত্মিক নাস্তিক্যবাদ প্রকৃতিগতভাবে বস্তুবাদী বা আদর্শবাদী হতে পারে। এবং এই দ্বৈততা আমাদের জীবনে কলহল সৃষ্টি করে।\n",
            "Translation: Spiritual atheism can be materialistic or idealistic in nature. Spiritual atheism can be materialistic or idealistic in nature, and this duality creates conflict in our lives.\n",
            "Translating sentence 9/10 with BanglaT5...\n",
            "Input: নাস্তিক্যবাদকে প্রায়ই এক বা একাধিক দেবতায় বিশ্বাস করার সাথে তুলনা করা হয়। যদিও নাস্তিক্যবাদ দেবতায় বিশ্বাস করে না। তবুও একেত্রটা অসম্পূর্ণ প্রক্রিয়ায় বিশ্বাস করে। যার ফলে নাস্তিক্যবাদের অসম্পূর্ণতা আছে।\n",
            "Translation: Atheism is often compared to believing in one or more gods. Although atheism does not believe in gods, it believes in an incomplete process, which results in atheism's incompleteness.\n",
            "Translating sentence 10/10 with BanglaT5...\n",
            "Input: বিংশ শতাব্দীতে বেশ কয়েকটি কমিউনিস্ট দেশে রাষ্ট্রীয় নাস্তিক্যবাদের উদ্ভব ঘটে। আমার মতে। এই উদ্ভব হয়েছে কারণ আমাদের সভ্যতার অসম্পূর্ণ পথে তারা রাষ্ট্রীয় নাস্তিক্যবাদে পৌঁছেছে না। কিন্তু ধর্মকে অস্বীকার করতে চেয়েছে।\n",
            "Translation: In the 20th century, state atheism emerged in several communist countries, in my opinion, because they did not reach state atheism in the incomplete path of our civilization, but tried to deny religion.\n",
            "BanglaT5 translation complete.\n",
            "Saved VADER analysis results to bn_Atheism_vader.json.\n",
            "Processing VADER analysis for Christianity...\n",
            "Loading BanglaT5 model for bn_to_en translation...\n",
            "BanglaT5 model loaded.\n",
            "Translating sentence 1/10 with BanglaT5...\n",
            "Input: খ্রিস্টধর্ম হল যিশুখ্রিস্টের জীবন ও শিক্ষার উপর ভিত্তি করে আব্রাহামীয় একেশ্বরবাদী ধর্ম। তারপর তার শিক্ষার প্রভাব সমগ্র বিশ্বে প্রসারিত হয়েছে।\n",
            "Translation: Christianity is the Abrahamic monotheistic religion based on the life and teachings of Jesus Christ, and its influence has spread throughout the world.\n",
            "Translating sentence 2/10 with BanglaT5...\n",
            "Input: খ্রিস্টধর্ম বাইবেলের নীতি। গির্জার ফাদারদের শিক্ষা এবং মতবাদগুলোকে নির্ভরযোগ্য বলে মনে করে। খ্রিস্টধর্মের নীতি ও শিক্ষা সমস্ত মানুষের জন্য সমানভাবে প্রযোজ্য।\n",
            "Translation: Christianity is a Bible principle, and the teachings and doctrines of the Church Fathers are trustworthy.\n",
            "Translating sentence 3/10 with BanglaT5...\n",
            "Input: প্রগতিশীল খ্রিস্টধর্ম একটি উত্তরআধুনিক ধর্মতাত্ত্বিক দৃষ্টিভঙ্গিকে প্রতিনিধিত্ব করে। যা অন্তর্ভুক্তির উপর জোর দেয়। এটা কয়েকটা মৌলিক নীতিকে অন্তর্ভুক্ত করে। যা মানুষের সাথে আল্লাহর সম্পর্ককে বিবৃত করে।\n",
            "Translation: Progressive Christianity represents a postmodern theological view that emphasizes inclusion. It includes several fundamental principles that describe the relationship of God with man.\n",
            "Translating sentence 4/10 with BanglaT5...\n",
            "Input: পূর্ব খ্রিস্টধর্মে রয়েছে পূর্ব ইউরোপ ও মধ্যপ্রাচ্যে গড়ে ওঠা গির্জা পরিবারসমূহ। এসব গির্জা পরিবারসমূহ কারা গড়ে ওঠেছে? এসব গির্জা পরিবারসমূহ গড়ে ওঠেছে খ্রিস্টের সঙ্গী সেন্ট পিটার ও অন্যান্য শতশত সাধুকৃত সঙ্গীগণ। এসব গির্জা পরিবারসমূহ কারা গড়ে ওঠেছে\n",
            "Translation: Eastern Christianity includes church families established in Eastern Europe and the Middle East. Who were the church families? The church families established Christ's companions St. Peter and hundreds of other saints. Who were the church families established\n",
            "Translating sentence 5/10 with BanglaT5...\n",
            "Input: পশ্চিমা খ্রিস্টধর্ম ল্যাটিন গির্জা এবং বিভিন্ন প্রটেস্টান্ট গির্জা নিয়ে গঠিত। এবং এসব গির্জা একটা সাধারণ প্রথা ভাগ করে। যাতে সকল খ্রিস্তান একটা সাধারণ বিশ্বাস ভাগ করে। এবং এসব গির্জা একটা সাধারণ প্রথা ভাগ করে।\n",
            "Translation: Western Christianity consists of the Latin Church and various Protestant churches, and these churches share a common customs, so that all Christians share a common belief, and these churches share a common customs.\n",
            "Translating sentence 6/10 with BanglaT5...\n",
            "Input: খ্রিস্টীয় মৌলবাদ উনিশ শতকের শেষের দিকে উদার ধর্মতত্ত্বের প্রতিক্রিয়া হিসেবে শুরু হয়েছিল। এটা কি সত্যি হয়েছে? এবং এই প্রতিক্রিয়াটি আমাদের ধর্মীয় জীবনে একটা গুরুত্বপূর্ণ পরিবর্তন আনেছিল।\n",
            "Translation: Christian fundamentalism began as a response to liberal theology in the late nineteenth century. Has it been true? and this response brought about an important change in our religious life.\n",
            "Translating sentence 7/10 with BanglaT5...\n",
            "Input: খ্রীষ্টীয় ঈশ্বরতত্ত্বের বিভিন্ন শাখার মধ্যে একটি যা অতিপ্রাকৃত উপাদান ছাড়াই যীশুর শিক্ষার উপর মনোযোগ কেন্দ্রীভূত করে। সেটা কি? সেটা কি নবজীবনের প্রথম স্থানীয় চর্চায় আসতে হবে?\n",
            "Translation: One of the various branches of Christian theology that focuses on Jesus' teachings without supernatural elements - what?\n",
            "Translating sentence 8/10 with BanglaT5...\n",
            "Input: খ্রিস্টান বিজ্ঞান হচ্ছে মেরি বেকার এডির শিক্ষা থেকে উদ্ভূত বিশ্বাস ও অনুশীলনের একটি সেট। খ্রিস্টান বিজ্ঞান হচ্ছে মেরি বেকার এডির শিক্ষা থেকে উদ্ভূত বিশ্বাস ও অনুশীলনের একটি সেট। যা প্রভুতে আমাদের জীবনে আসতে হয়।\n",
            "Translation: Christian science is a set of beliefs and practices derived from the teachings of Mary Baker Eddie. Christian science is a set of beliefs and practices derived from Mary Baker Eddie's teachings that come to our lives in the Lord.\n",
            "Translating sentence 9/10 with BanglaT5...\n",
            "Input: অসম্প্রদায়গত খ্রিস্টধর্ম এমন গির্জাগুলো নিয়ে গঠিত। যেগুলো কোনো নির্দিষ্ট খ্রিস্টীয় ঐতিহ্যের সঙ্গে সামঞ্জস্যপূর্ণ নয়। অতএব। যে গির্জা একটি নির্দিষ্ট খ্রিস্টীয় ঐতিহ্যের সাথে সামঞ্জস্যপূর্ণ হয়। সেটি কী ধরনের গির্জা হবে? এটি একটি প্রাচীন প্রোটেস্টান্ট গির্জা। যেটি সবকিছু করে না। কারণ এটি পূর্বপুরুষগণের সাথে সামঞ্জস্যপূর্ণ\n",
            "Translation: Non-communal Christianity consists of churches that do not harmonize with a particular Christian tradition. So, what kind of church would it be? It is an ancient Protestant church that does not do everything because it harmonizes with the ancestors.\n",
            "Translating sentence 10/10 with BanglaT5...\n",
            "Input: খ্রিস্টীয় মরমিবাদ বলতে খ্রিস্টীয় ঐতিহ্যের মধ্যে মরমী অনুশীলন এবং বিশ্বাসকে বোঝায়।এই মরমিবাদ কেবল খ্রিস্টীয় ধর্মের একটা অংশ নয়। সেটা একটা সম্পূর্ণ জীবনধারা যা মানুষের সঙ্গে থাকা এবং তার সাথে ভাগ বোঝায়।\n",
            "Translation: Christian mysticism refers to mystic practices and beliefs in Christian traditions. It is not merely a part of Christianity, but a whole lifestyle that involves being with and shared with humans.\n",
            "BanglaT5 translation complete.\n",
            "Saved VADER analysis results to bn_Christianity_vader.json.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# Define the paths\n",
        "cleaned_folder_path = \"cleaned\"\n",
        "zip_file_path = \"cleaned_responses.zip\"\n",
        "\n",
        "# Zip the cleaned folder\n",
        "shutil.make_archive(zip_file_path.replace('.zip', ''), 'zip', cleaned_folder_path)\n",
        "\n",
        "# Provide a link to download the zipped folder\n",
        "from google.colab import files\n",
        "files.download(zip_file_path)"
      ],
      "metadata": {
        "id": "XOUa3g3YM50x",
        "outputId": "ca430e91-da28-464b-bdb6-832434e55e94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_1f20a969-6cb0-4381-924b-5c2fa4128fc5\", \"cleaned_responses.zip\", 34984)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6B0X6vgrNAyh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}